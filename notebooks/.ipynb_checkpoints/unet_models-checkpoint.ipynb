{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train U-Net models\n",
    "* Some issues with using keras for data augmentation, the standard functions may only support 3 channel images?\n",
    "\n",
    "### Manual Data Augmentation\n",
    "* First try using a simple augmentation strategy, only using "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import glob\n",
    "from scipy.ndimage import rotate\n",
    "from PIL import Image\n",
    "\n",
    "import keras\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "from keras.engine.topology import Layer\n",
    "from keras import metrics\n",
    "from keras import layers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout, Flatten, Reshape, Input, concatenate, Conv2DTranspose\n",
    "from keras.layers.core import Activation, Dense, Lambda\n",
    "from keras.constraints import maxnorm\n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D, AveragePooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "\n",
    "\n",
    "############ DATA GENERATORS\n",
    "def data_gen_aug_combined(file_loc, mask_loc, batch_size, square_rot_p=.3, seed=101):\n",
    "    # square_rot_p is the prob of using a 90x rotation, otherwise sample from 360. Possibly not useful\n",
    "    # translate is maximum number of pixels to translate by\n",
    "    # crops are done \n",
    "    square_rot_p = int(square_rot_p)\n",
    "    np.random.seed(seed)\n",
    "    all_files=glob.glob(os.path.join(file_loc, '*'))\n",
    "    all_masks=[]\n",
    "\n",
    "    all_files = [loc for loc in all_files if loc.rsplit('.', 1)[-1] in ['tif']]\n",
    "\n",
    "#     for file in all_files:\n",
    "#         im_name = str(file.rsplit('.', 1)[-2].rsplit('/', 1)[1].rsplit('_', 1)[0].replace(\" \", \"_\"))\n",
    "#         loc = os.path.join(mask_loc, im_name+'.npy')\n",
    "#         all_masks.append(loc)\n",
    "        \n",
    "    for file in all_files:\n",
    "        im_name = str(file.rsplit('.', 1)[-2].rsplit('/', 1)[1])\n",
    "        loc = os.path.join(mask_loc, im_name+'.tif')\n",
    "        all_masks.append(loc)\n",
    "\n",
    "    while 1:\n",
    "        c = list(zip(all_files, all_masks))\n",
    "        np.random.shuffle(c)\n",
    "        all_files, all_masks = zip(*c)\n",
    "\n",
    "        num_batches = int(np.floor(len(all_files)/batch_size))-1\n",
    "\n",
    "        for batch in range(num_batches):\n",
    "            x=[]\n",
    "            y=[]\n",
    "            batch_files = all_files[batch_size*batch:batch_size*(batch+1)]\n",
    "            batch_files_mask = all_masks[batch_size*batch:batch_size*(batch+1)]\n",
    "\n",
    "            for index in range(len(batch_files)):\n",
    "                image_loc = batch_files[index]\n",
    "                mask_loc = batch_files_mask[index]\n",
    "\n",
    "                # load the image\n",
    "                image = Image.open(image_loc)\n",
    "                width, height = image.size\n",
    "                image = np.reshape(np.array(image.getdata()), (height, width, 3))\n",
    "\n",
    "                #load the mask\n",
    "                mask = Image.open(mask_loc)\n",
    "                width, height = mask.size\n",
    "                mask = np.reshape(np.array(mask.getdata()), (height, width, 4))\n",
    "                \n",
    "                # All the randomness:\n",
    "                height, width = np.shape(image)[0], np.shape(image)[1]\n",
    "                crop_row = np.random.randint(0, height-320)\n",
    "                crop_col = np.random.randint(0, width-368)\n",
    "                flip_vert = np.random.randint(0, 2)\n",
    "                flip_hor = np.random.randint(0, 2)\n",
    "\n",
    "                # APPLY AUGMENTATION:\n",
    "                # flips\n",
    "                if flip_vert:\n",
    "                    image = np.flipud(image)\n",
    "                    mask = np.flipud(mask)\n",
    "\n",
    "                if flip_hor:\n",
    "                    image = np.fliplr(image)\n",
    "                    mask = np.fliplr(mask)\n",
    "\n",
    "                # rotation\n",
    "                square_rot =  bool((np.random.uniform(0, 1, 1)<square_rot_p))\n",
    "                if square_rot:  # maybe this is dumb, but it cant hurt\n",
    "                    rotations=['0', '90', '180', '270']\n",
    "                    angle = int(random.choice(rotations))\n",
    "                    image = rotate(image, angle, reshape=False)\n",
    "                    mask = rotate(mask, angle, reshape=False)\n",
    "\n",
    "                else:\n",
    "                    angle = np.random.uniform(0, 360, 1)\n",
    "                    image = rotate(image, angle, reshape=False)\n",
    "                    mask = rotate(mask, angle, reshape=False)\n",
    " \n",
    "                # crop to 320 x 360 so it will fit into network, and for data augmentation\n",
    "                image = image[crop_row:crop_row+320, crop_col:crop_col+368]\n",
    "                mask = mask[crop_row:crop_row+320, crop_col:crop_col+368]\n",
    "\n",
    "                image = image/255.0 # make pixels in [0,1] \n",
    "                x.append(image)\n",
    "                y.append(mask)\n",
    "            x=np.array(x)\n",
    "            y=np.array(y)\n",
    "            yield (x, y)\n",
    "\n",
    "\n",
    "def data_gen_combined(file_loc, mask_loc, batch_size, seed=101):\n",
    "    np.random.seed(seed)\n",
    "    all_files=glob.glob(os.path.join(file_loc, '*'))\n",
    "    all_masks=[]\n",
    "    for file in all_files:\n",
    "        im_name = str(file.rsplit('.', 1)[-2].rsplit('/', 1)[1])\n",
    "        loc = os.path.join(mask_loc, im_name+'.tif')\n",
    "        all_masks.append(loc)\n",
    "\n",
    "    all_files = [loc for loc in all_files if loc.rsplit('.', 1)[-1] in ['tif']]\n",
    "\n",
    "    while 1:\n",
    "        c = list(zip(all_files, all_masks))\n",
    "        np.random.shuffle(c)\n",
    "        all_files, all_masks = zip(*c)\n",
    "        \n",
    "        num_batches = int(np.floor(len(all_files)/batch_size))-1\n",
    "        for batch in range(num_batches):\n",
    "            x=[]\n",
    "            y=[]\n",
    "            batch_files = all_files[batch_size*batch:batch_size*(batch+1)]\n",
    "            batch_files_mask = all_masks[batch_size*batch:batch_size*(batch+1)]\n",
    "\n",
    "            for index in range(len(batch_files)):\n",
    "                image_loc = batch_files[index]\n",
    "                mask_loc = batch_files_mask[index]\n",
    "\n",
    "                # load the image\n",
    "                image = Image.open(image_loc)\n",
    "                width, height = image.size\n",
    "                image = np.reshape(np.array(image.getdata()), (height, width, 3))\n",
    "\n",
    "                #load the mask\n",
    "                mask = Image.open(mask_loc)\n",
    "                width, height = mask.size\n",
    "                mask = np.reshape(np.array(mask.getdata()), (height, width, 4))\n",
    "                \n",
    "                ################################ IMPLEMENT::::\n",
    "                # We will pad the imput to make them all the same size:\n",
    "                \n",
    "                # make it the same size as the training examples\n",
    "                height, width = np.shape(image)[0], np.shape(image)[1]\n",
    "                crop_row = np.random.randint(0, height-320)\n",
    "                crop_col = np.random.randint(0, width-368)\n",
    "\n",
    "                # crop to 320 x 360 so it will fit into network, and for data augmentation\n",
    "                image = image[crop_row:crop_row+320, crop_col:crop_col+368]\n",
    "                mask = mask[crop_row:crop_row+320, crop_col:crop_col+368]\n",
    "\n",
    "                image = image/255.0 # make pixels in [0,1]     \n",
    "                x.append(image)\n",
    "                y.append(mask)\n",
    "\n",
    "            x=np.array(x)\n",
    "            y=np.array(y)\n",
    "            yield (x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models\n",
    "\n",
    "#### Loss\n",
    "Loss Function is different than the usual dice coefficient. We won't measure overlap. It is made of two parts:\n",
    "1. MSE on the distance to the nearest nuclei.\n",
    "2. Class of the nearest nuclei\n",
    "Both of these parts should be 0 if the nearest nuclei is over 20 pixels away? At least I think so. For sure the distance is meaningless, and the classifation would just add some noise to the model.\n",
    "\n",
    "#### Model\n",
    "* Test a models smaller and larger than the original U-Net.\n",
    "* Try adding batchnorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distance loss function\n",
    "def distance_loss(y_true, y_pred):\n",
    "    weight = .5 # how mush does the distance matter compared to the cross entropy (fast ai used .001 for 4 more uncertain ones)\n",
    "    # Already scaled distance values between (0,1). Cut off ones larger because this doesn't hurt the prediction\n",
    "#     K.int_shape(y_true)\n",
    "#     K.int_shape(y_pred)\n",
    "#     y_pred_clip = K.clip(y_pred[:, :, 0], -1, 1)\n",
    "#     K.int_shape(y_pred_clip)\n",
    "    distance_loss = K.binary_crossentropy(y_pred[:, :, :, 0], y_true[:, :, :, 0])\n",
    "#     K.int_shape(distance_loss)\n",
    "    \n",
    "    cross_entropy = K.categorical_crossentropy(y_true[:, :, :, 1:], y_pred[:, :, :, 1:])    \n",
    "#     K.int_shape(cross_entropy)\n",
    "\n",
    "    return(distance_loss*weight+(1-weight)*cross_entropy)\n",
    "\n",
    "\n",
    "# Remove all the predictions from the cost that are under 20 away for cross entropy. Not for MSE because it should learn easily\n",
    "# def distance_loss_under20(y_true, y_pred):\n",
    "#     weight = .05 # how mush does the distance matter compared to the cross entropy (fast ai used .001 for 4 more uncertain ones)\n",
    "#     # Clip the distance values to be less than 20 :\n",
    "#     y_pred[:, :, 0] = K.clip(y_pred[:, :, 0], -1, 1)\n",
    "#     mse = K.mean(K.square(y_pred[:, :, 0] - y_true[:, :, 0]), axis=-1)\n",
    "    \n",
    "#     # Only look at the elements with a distance of less than 20  pixels from the nuclei.\n",
    "#     y_true_clip = \n",
    "#     y_pred_clip = \n",
    "#     cross_entropy = categorical_crossentropy(y_true[:, :, 1:], y_pred[:, :, 1:])    \n",
    "#     return(mse*weight+(1-weight)*cross_entropy)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "############ UNET ARCHITECTURES \n",
    "\n",
    "def unet_standard(learning_rate=.0001):\n",
    "    input_shape = (None, None, 3)\n",
    "    img_input = Input(shape=input_shape)\n",
    "    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(img_input)\n",
    "    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "\n",
    "    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(pool1)\n",
    "    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "\n",
    "    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(pool2)\n",
    "    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv3)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "\n",
    "    conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(pool3)\n",
    "    conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv4)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n",
    "\n",
    "    conv5 = Conv2D(512, (3, 3), activation='relu', padding='same')(pool4)\n",
    "    conv5 = Conv2D(512, (3, 3), activation='relu', padding='same')(conv5)\n",
    "\n",
    "    up6 = concatenate([Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(conv5), conv4], axis=3)\n",
    "    conv6 = Conv2D(256, (3, 3), activation='relu', padding='same')(up6)\n",
    "    conv6 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv6)\n",
    "\n",
    "    up7 = concatenate([Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(conv6), conv3], axis=3)\n",
    "    conv7 = Conv2D(128, (3, 3), activation='relu', padding='same')(up7)\n",
    "    conv7 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv7)\n",
    "\n",
    "    up8 = concatenate([Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(conv7), conv2], axis=3)\n",
    "    conv8 = Conv2D(64, (3, 3), activation='relu', padding='same')(up8)\n",
    "    conv8 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv8)\n",
    "\n",
    "    up9 = concatenate([Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(conv8), conv1], axis=3)\n",
    "    conv9 = Conv2D(32, (3, 3), activation='relu', padding='same')(up9)\n",
    "    conv9 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv9)\n",
    "\n",
    "    conv10_dist = Conv2D(1, (1, 1), activation='sigmoid')(conv9)\n",
    "    conv10_cross_entropy = Conv2D(3, (1, 1), activation='softmax')(conv9)\n",
    "    output = concatenate([conv10_dist, conv10_cross_entropy])\n",
    "\n",
    "    model = Model(img_input, output)\n",
    "    model.compile(optimizer=Adam(lr=learning_rate), loss=distance_loss, metrics=[distance_loss])\n",
    "    return model\n",
    "\n",
    "def unet_mid(learning_rate=.0001):\n",
    "    input_shape = (None, None, 3)\n",
    "    img_input = Input(shape=input_shape)\n",
    "    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(img_input)\n",
    "    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "\n",
    "    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(pool1)\n",
    "    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "\n",
    "    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(pool2)\n",
    "    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv3)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "\n",
    "    conv5 = Conv2D(256, (3, 3), activation='relu', padding='same')(pool4)\n",
    "    conv5 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv5)\n",
    "\n",
    "    up6 = concatenate([Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(conv5), conv3], axis=3)\n",
    "    conv6 = Conv2D(128, (3, 3), activation='relu', padding='same')(up6)\n",
    "    conv6 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv6)\n",
    "\n",
    "    up7 = concatenate([Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(conv6), conv2], axis=3)\n",
    "    conv7 = Conv2D(64, (3, 3), activation='relu', padding='same')(up7)\n",
    "    conv7 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv7)\n",
    "\n",
    "    up8 = concatenate([Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(conv7), conv1], axis=3)\n",
    "    conv8 = Conv2D(32, (3, 3), activation='relu', padding='same')(up8)\n",
    "    conv8 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv8)\n",
    "\n",
    "    conv9_dist = Conv2D(1, (1, 1), activation='sigmoid')(conv8)\n",
    "    conv9_cross_entropy = Conv2D(3, (1, 1), activation='softmax')(conv8)\n",
    "    output = concatenate([conv9_dist, conv9_cross_entropy])\n",
    "\n",
    "    model = Model(img_input, output)\n",
    "    model.compile(optimizer=Adam(lr=learning_rate), loss=distance_loss, metrics=[distance_loss])\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def conv_block(x,\n",
    "              filters,\n",
    "              num_row,\n",
    "              num_col,\n",
    "              dropout, \n",
    "              padding='same',\n",
    "              strides=(1, 1),\n",
    "              activation='relu'):\n",
    "    x = Conv2D(filters, (num_row, num_col), strides=strides, padding=padding, activation=activation)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Dropout(dropout)(x)\n",
    "\n",
    "    x = Conv2D(filters, (num_row, num_col), strides=strides, padding=padding, activation=activation)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Dropout(dropout)(x)\n",
    "    return x\n",
    "\n",
    "def unet_paper(learning_rate=.0001):\n",
    "    input_shape = (None, None, 3)\n",
    "    img_input = Input(shape=input_shape)\n",
    "\n",
    "    conv1 = conv_block(img_input, 32, 3, 3, dropout = .1, padding='same', strides=(1, 1), activation='relu')\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "\n",
    "    conv2 = conv_block(pool1, 64, 3, 3, dropout = .1, padding='same', strides=(1, 1), activation='relu')\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "\n",
    "    conv3 = conv_block(pool2, 128, 3, 3, dropout = .1, padding='same', strides=(1, 1), activation='relu')\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "\n",
    "    conv4 = conv_block(pool3, 128, 3, 3, dropout = .1, padding='same', strides=(1, 1), activation='relu')\n",
    "\n",
    "    up5 = concatenate([Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(conv4), conv3], axis=3)\n",
    "    conv5 = conv_block(up5, 128, 3, 3, dropout = .1, padding='same', strides=(1, 1), activation='relu')\n",
    "\n",
    "    up6 = concatenate([Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(conv5), conv2], axis=3)\n",
    "    conv6 = conv_block(up6, 64, 3, 3, dropout = .1, padding='same', strides=(1, 1), activation='relu')\n",
    "\n",
    "    up7 = concatenate([Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(conv6), conv1], axis=3)\n",
    "    conv7 = conv_block(up7, 32, 3, 3, dropout = .1, padding='same', strides=(1, 1), activation='relu')\n",
    "    \n",
    "    conv8_dist = Conv2D(1, (1, 1), activation='sigmoid')(conv7)\n",
    "    conv8_cross_entropy = Conv2D(3, (1, 1), activation='softmax')(conv7)\n",
    "    output = concatenate([conv8_dist, conv8_cross_entropy])\n",
    "    \n",
    "    model = Model(img_input, output)\n",
    "    model.compile(optimizer=Adam(lr=learning_rate), loss=distance_loss, metrics=[distance_loss])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/rbbidart/project/rbbidart/cancer_hist/full_slides2/valid/0\n",
      "num_train 87.0\n",
      "num_valid 20.0\n",
      "validation_steps 2.0\n",
      "Epoch 1/100\n",
      " 9/10 [==========================>...] - ETA: 185s - loss: 141.8302 - distance_loss: 141.8302"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-5:\n",
      "Traceback (most recent call last):\n",
      "  File \"/cvmfs/soft.computecanada.ca/nix/store/v29pphgl66qjvjck1mn4pcm5g9agk5kh-python3-3.5.2/lib/python3.5/threading.py\", line 914, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/cvmfs/soft.computecanada.ca/nix/store/v29pphgl66qjvjck1mn4pcm5g9agk5kh-python3-3.5.2/lib/python3.5/threading.py\", line 862, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/rbbidart/tensorflow2/lib/python3.5/site-packages/keras/utils/data_utils.py\", line 568, in data_generator_task\n",
      "    generator_output = next(self._generator)\n",
      "  File \"<ipython-input-1-1ba4f1cb8e10>\", line 120, in data_gen_combined\n",
      "    all_masks.append(loc)\n",
      "UnboundLocalError: local variable 'all_masks' referenced before assignment\n",
      "\n"
     ]
    },
    {
     "ename": "StopIteration",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-50177323913f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     56\u001b[0m                                   \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m                                   \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m                                   callbacks=callbacks)\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tensorflow2/lib/python3.5/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     86\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 87\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tensorflow2/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2062\u001b[0m                                 \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2063\u001b[0m                                 \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2064\u001b[0;31m                                 use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m   2065\u001b[0m                         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2066\u001b[0m                             \u001b[0;31m# No need for try/except because\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tensorflow2/lib/python3.5/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     86\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 87\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tensorflow2/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate_generator\u001b[0;34m(self, generator, steps, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   2158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2159\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0msteps_done\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2160\u001b[0;31m                 \u001b[0mgenerator_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2161\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__len__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2162\u001b[0m                     raise ValueError('Output of generator should be a tuple '\n",
      "\u001b[0;31mStopIteration\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import random\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import keras\n",
    "import pickle\n",
    "from keras import backend as K\n",
    "from keras.engine.topology import Layer\n",
    "from keras.layers import Dropout, Flatten, Reshape, Input\n",
    "from keras.layers.core import Activation, Dense, Lambda\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "learning_rate=.005\n",
    "epochs=100\n",
    "batch_size=8\n",
    "data_loc='/home/rbbidart/project/rbbidart/cancer_hist/full_slides2'\n",
    "mask_loc='/home/rbbidart/project/rbbidart/cancer_hist/im_dist_labels'\n",
    "out_loc='/home/rbbidart/cancer_hist_out/unet_dist/unet_paper_custom_aug'\n",
    "\n",
    "\n",
    "# Locations\n",
    "train_loc = os.path.join(str(data_loc),'train', str(0))\n",
    "train_mask_loc = os.path.join(str(mask_loc),'train', str(0))\n",
    "\n",
    "valid_loc = os.path.join(str(data_loc),'valid', str(0))\n",
    "valid_mask_loc = os.path.join(str(mask_loc),'valid', str(0))\n",
    "\n",
    "num_train = len(glob.glob(os.path.join(train_loc, '*')))/2-2\n",
    "num_valid = len(glob.glob(os.path.join(valid_loc, '*')))/2-2\n",
    "print(valid_loc)\n",
    "print('num_train', num_train)\n",
    "print('num_valid', num_valid)\n",
    "\n",
    "# Params for all models\n",
    "batch_size=int(batch_size)   # make this divisible by len(x_data)\n",
    "steps_per_epoch = np.floor(num_train/batch_size) # num of batches from generator at each epoch. (make it full train set)\n",
    "validation_steps = np.floor(num_valid/batch_size)# size of validation dataset divided by batch size\n",
    "print('validation_steps', validation_steps)\n",
    "\n",
    "model = unet_paper(learning_rate=learning_rate)\n",
    "name = 'unet_paper'+'_'+str(learning_rate)+'_'+'custom_aug'\n",
    "out_file=os.path.join(str(out_loc), name)\n",
    "\n",
    "# need a batch generator to augment the labels same as the train images\n",
    "valid_generator = data_gen_combined(valid_loc, valid_mask_loc, batch_size, seed=101)\n",
    "train_generator = data_gen_aug_combined(train_loc, train_mask_loc, batch_size, square_rot_p=.3,  seed=101)\n",
    "\n",
    "callbacks = [EarlyStopping(monitor='distance_loss', patience=15, verbose=0),\n",
    "        ModelCheckpoint(filepath=os.path.join(out_loc, name + '_.{epoch:02d}-{val_acc:.2f}.hdf5'), \n",
    "        verbose=1, monitor='val_loss', save_best_only=True)]\n",
    "\n",
    "hist = model.fit_generator(train_generator,\n",
    "                                  validation_data=valid_generator,\n",
    "                                  steps_per_epoch=steps_per_epoch, \n",
    "                                  epochs=epochs,\n",
    "                                  validation_steps=validation_steps,\n",
    "                                  callbacks=callbacks)\n",
    "pickle.dump(hist.history, open(out_file, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import random\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import keras\n",
    "import pickle\n",
    "from keras import backend as K\n",
    "from keras.engine.topology import Layer\n",
    "from keras.layers import Dropout, Flatten, Reshape, Input\n",
    "from keras.layers.core import Activation, Dense, Lambda\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "learning_rate=.005\n",
    "epochs=100\n",
    "batch_size=8\n",
    "data_loc='/home/rbbidart/project/rbbidart/cancer_hist/full_slides2'\n",
    "mask_loc='/home/rbbidart/project/rbbidart/cancer_hist/im_dist_labels'\n",
    "out_loc='/home/rbbidart/cancer_hist_out/unet_dist/unet_standard_custom_aug'\n",
    "\n",
    "\n",
    "# Locations\n",
    "train_loc = os.path.join(str(data_loc),'train', str(0))\n",
    "train_mask_loc = os.path.join(str(mask_loc),'train', str(0))\n",
    "\n",
    "valid_loc = os.path.join(str(data_loc),'valid', str(0))\n",
    "valid_mask_loc = os.path.join(str(mask_loc),'valid', str(0))\n",
    "\n",
    "num_train = len(glob.glob(os.path.join(train_loc, '*')))/2-2\n",
    "num_valid = len(glob.glob(os.path.join(valid_loc, '*')))/2-2\n",
    "print(valid_loc)\n",
    "print('num_train', num_train)\n",
    "print('num_valid', num_valid)\n",
    "\n",
    "# Params for all models\n",
    "batch_size=int(batch_size)   # make this divisible by len(x_data)\n",
    "steps_per_epoch = np.floor(num_train/batch_size) # num of batches from generator at each epoch. (make it full train set)\n",
    "validation_steps = np.floor(num_valid/batch_size)# size of validation dataset divided by batch size\n",
    "print('validation_steps', validation_steps)\n",
    "\n",
    "model = unet_standard(learning_rate=learning_rate)\n",
    "name = 'unet_standard'+'_'+str(learning_rate)+'_'+'custom_aug'\n",
    "out_file=os.path.join(str(out_loc), name)\n",
    "\n",
    "# need a batch generator to augment the labels same as the train images\n",
    "valid_generator = data_gen_combined(valid_loc, valid_mask_loc, batch_size, seed=101)\n",
    "train_generator = data_gen_aug_combined(train_loc, train_mask_loc, batch_size, square_rot_p=.3,  seed=101)\n",
    "\n",
    "callbacks = [EarlyStopping(monitor='distance_loss', patience=15, verbose=0),\n",
    "        ModelCheckpoint(filepath=os.path.join(out_loc, name + '_.{epoch:02d}-{val_acc:.2f}.hdf5'), \n",
    "        verbose=1, monitor='val_loss', save_best_only=True)]\n",
    "\n",
    "hist = model.fit_generator(train_generator,\n",
    "                                  validation_data=valid_generator,\n",
    "                                  steps_per_epoch=steps_per_epoch, \n",
    "                                  epochs=epochs,\n",
    "                                  validation_steps=validation_steps,\n",
    "                                  callbacks=callbacks)\n",
    "pickle.dump(hist.history, open(out_file, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "data_loc = '/home/rbbidart/project/rbbidart/cancer_hist/full_slides2'\n",
    "out_loc = '/home/rbbidart/project/rbbidart/cancer_hist/full_slides2_k'\n",
    "\n",
    "all_images=glob.glob(data_loc + '/**/*.tif', recursive=True)\n",
    "for image_file in all_images:\n",
    "    name = image_file.rsplit('/', 1)[-1].rsplit('.', 1)[0]\n",
    "    new_loc = image_file.rsplit('/', 1)[0].replace('full_slides2', 'full_slides2_k')\n",
    "    if not os.path.exists(new_loc):\n",
    "        os.makedirs(new_loc)\n",
    "    new_name = name+'.jpg'\n",
    "    im = Image.open(image_file)\n",
    "    im.save(os.path.join(new_loc, new_name))\n",
    "    \n",
    "data_loc = '/home/rbbidart/project/rbbidart/cancer_hist/im_dist_labels'\n",
    "out_loc = '/home/rbbidart/project/rbbidart/cancer_hist/im_dist_labels_k'\n",
    "all_images=glob.glob(data_loc + '/**/*.tif', recursive=True)\n",
    "for image_file in all_images:\n",
    "    name = image_file.rsplit('/', 1)[-1].rsplit('.', 1)[0]\n",
    "    new_loc = image_file.rsplit('/', 1)[0].replace('im_dist_labels', 'im_dist_labels_k')\n",
    "    if not os.path.exists(new_loc):\n",
    "        os.makedirs(new_loc)\n",
    "    new_name = name+'.jpg'\n",
    "    im = Image.open(image_file)\n",
    "    im.save(os.path.join(new_loc, new_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "def get_generator(train_folder, train_mask_folder, valid_folder, valid_mask_folder,\n",
    "                    width_shift_range=0.2,\n",
    "                    height_shift_range=0.2,\n",
    "                    horizontal_flip=True,\n",
    "                    rotation_range=10,\n",
    "                    zoom_range=0.2,\n",
    "                    classes=['keras'],\n",
    "                    fill_mode=\"constant\"):\n",
    "    batch_size = 4\n",
    "    seed = 42\n",
    "    # Example taken from https://keras.io/preprocessing/image/\n",
    "    # We create two instances with the same arguments\n",
    "    data_gen_args_train = dict(\n",
    "                        width_shift_range=width_shift_range,\n",
    "                        height_shift_range=height_shift_range,\n",
    "                        horizontal_flip=horizontal_flip,\n",
    "                        rotation_range=rotation_range,\n",
    "                        zoom_range=zoom_range,\n",
    "                        fill_mode=fill_mode, \n",
    "                        cval=0       \n",
    "                        )\n",
    "    data_gen_args_masks = dict(\n",
    "                        width_shift_range=width_shift_range,\n",
    "                        height_shift_range=height_shift_range,\n",
    "                        horizontal_flip=horizontal_flip,\n",
    "                        rotation_range=rotation_range,\n",
    "                        zoom_range=zoom_range,\n",
    "                        fill_mode=fill_mode,\n",
    "                        cval=0    \n",
    "                        )\n",
    "    image_datagen = ImageDataGenerator(**data_gen_args_train)\n",
    "    mask_datagen = ImageDataGenerator(**data_gen_args_masks)\n",
    "    image_generator = image_datagen.flow_from_directory(\n",
    "        train_folder,\n",
    "        batch_size = batch_size,\n",
    "        target_size = (640, 800),\n",
    "        class_mode=None,\n",
    "        color_mode='rgb',\n",
    "        classes=classes,\n",
    "        seed=seed)\n",
    "    mask_generator = mask_datagen.flow_from_directory(\n",
    "        train_mask_folder,\n",
    "        batch_size = batch_size,    \n",
    "        target_size = (640, 800),    \n",
    "        class_mode=None,\n",
    "        color_mode='grayscale',\n",
    "        classes=classes,\n",
    "        seed=seed)\n",
    "    valid_image_generator = image_datagen.flow_from_directory(\n",
    "        valid_folder,\n",
    "        batch_size = batch_size,\n",
    "        target_size = (640, 800),\n",
    "        class_mode=None,\n",
    "        color_mode='rgb',\n",
    "        classes=classes,\n",
    "        seed=seed)\n",
    "    valid_mask_generator = mask_datagen.flow_from_directory(\n",
    "        valid_mask_folder,\n",
    "        batch_size = batch_size,    \n",
    "        target_size = (640, 800),    \n",
    "        class_mode=None,\n",
    "        color_mode='grayscale',\n",
    "        classes=classes,\n",
    "        seed=seed)\n",
    "    # combine generators into one which yields image and masks\n",
    "    train_generator = zip(image_generator, mask_generator)\n",
    "    valid_generator = zip(valid_image_generator, valid_mask_generator)   \n",
    "    return train_generator,valid_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_loc='/home/rbbidart/cancer_hist_out/unet_dist/unet_standard_keras_aug'\n",
    "learning_rate=.005\n",
    "epochs=100\n",
    "batch_size=8\n",
    "data_loc='/home/rbbidart/project/rbbidart/cancer_hist/full_slides2_k'\n",
    "mask_loc='/home/rbbidart/project/rbbidart/cancer_hist/im_dist_labels_k'\n",
    "out_loc='/home/rbbidart/cancer_hist_out/unet_dist/unet_standard_custom_aug'\n",
    "\n",
    "\n",
    "train_loc = os.path.join(str(data_loc),'train')\n",
    "train_loc_mask = os.path.join(str(mask_loc),'train')\n",
    "\n",
    "valid_loc = os.path.join(str(data_loc),'valid')\n",
    "valid_loc_mask = os.path.join(str(mask_loc),'valid')\n",
    "\n",
    "\n",
    "train_generator,valid_generator=get_generator(train_loc, train_loc_mask, \n",
    "                                              valid_loc, valid_loc_mask,\n",
    "                    width_shift_range=0.2,\n",
    "                    height_shift_range=0.2,\n",
    "                    horizontal_flip=True,\n",
    "                    rotation_range=180,\n",
    "                    zoom_range=0.3,\n",
    "                    classes=['keras'],\n",
    "                    fill_mode=\"constant\")\n",
    "\n",
    "\n",
    "num_train = len(glob.glob(train_loc + '/**/*.png', recursive=True))\n",
    "num_valid = len(glob.glob(valid_loc + '/**/*.png', recursive=True))\n",
    "print(valid_loc)\n",
    "print('num_train', num_train)\n",
    "print('num_valid', num_valid)\n",
    "\n",
    "# Params for all models\n",
    "batch_size=int(batch_size)   # make this divisible by len(x_data)\n",
    "steps_per_epoch = np.floor(num_train/batch_size) # num of batches from generator at each epoch. (make it full train set)\n",
    "validation_steps = np.floor(num_valid/batch_size)# size of validation dataset divided by batch size\n",
    "print('validation_steps', validation_steps)\n",
    "\n",
    "model = unet_standard(learning_rate=learning_rate)\n",
    "name = 'unet_standard'+'_'+str(learning_rate)+'_'+'keras_aug'\n",
    "out_file=os.path.join(str(out_loc), name)\n",
    "\n",
    "# need a batch generator to augment the labels same as the train images\n",
    "valid_generator = data_gen_combined(valid_loc, valid_mask_loc, batch_size, seed=101)\n",
    "train_generator = data_gen_aug_combined(train_loc, train_mask_loc, batch_size, square_rot_p=.3,  seed=101)\n",
    "\n",
    "callbacks = [EarlyStopping(monitor='distance_loss', patience=15, verbose=0),\n",
    "        ModelCheckpoint(filepath=os.path.join(out_loc, name + '_.{epoch:02d}-{val_acc:.2f}.hdf5'), \n",
    "        verbose=1, monitor='val_loss', save_best_only=True)]\n",
    "\n",
    "hist = model.fit_generator(train_generator,\n",
    "                                  validation_data=valid_generator,\n",
    "                                  steps_per_epoch=steps_per_epoch, \n",
    "                                  epochs=epochs,\n",
    "                                  validation_steps=validation_steps,\n",
    "                                  callbacks=callbacks)\n",
    "pickle.dump(hist.history, open(out_file, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
