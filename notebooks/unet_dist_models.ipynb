{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import scipy.io\n",
    "import scipy.misc\n",
    "import matplotlib.pyplot as plt \n",
    "from matplotlib.pyplot import imshow\n",
    "from PIL import Image\n",
    "from bs4 import BeautifulSoup\n",
    "from collections import Counter\n",
    "from shutil import copyfile\n",
    "import random\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ '/home/rbbidart/project/rbbidart/cancer_hist/full_slides2/train/0/82_Region_4_crop.tif'\n",
      " '/home/rbbidart/project/rbbidart/cancer_hist/full_slides2/train/0/62_Region_3_crop.tif'\n",
      " '/home/rbbidart/project/rbbidart/cancer_hist/full_slides2/train/0/104_Region_6_crop.tif'\n",
      " '/home/rbbidart/project/rbbidart/cancer_hist/full_slides2/train/0/77_Region_1_crop.tif'\n",
      " '/home/rbbidart/project/rbbidart/cancer_hist/full_slides2/train/0/119_Region_15_crop.tif'\n",
      " '/home/rbbidart/project/rbbidart/cancer_hist/full_slides2/train/0/138_Region_9_crop.tif'\n",
      " '/home/rbbidart/project/rbbidart/cancer_hist/full_slides2/train/0/97_Region_5_crop.tif'\n",
      " '/home/rbbidart/project/rbbidart/cancer_hist/full_slides2/train/0/80_Region_9_crop.tif'\n",
      " '/home/rbbidart/project/rbbidart/cancer_hist/full_slides2/train/0/35_Region_1_crop.tif'\n",
      " '/home/rbbidart/project/rbbidart/cancer_hist/full_slides2/train/0/98_Region_7_crop.tif'\n",
      " '/home/rbbidart/project/rbbidart/cancer_hist/full_slides2/train/0/20_Region_67_crop.tif'\n",
      " '/home/rbbidart/project/rbbidart/cancer_hist/full_slides2/train/0/20_Region_67_crop.tif'\n",
      " '/home/rbbidart/project/rbbidart/cancer_hist/full_slides2/train/0/152_Region_2_crop.tif'\n",
      " '/home/rbbidart/project/rbbidart/cancer_hist/full_slides2/train/0/17_Region_60_crop.tif'\n",
      " '/home/rbbidart/project/rbbidart/cancer_hist/full_slides2/train/0/104_Region_6_crop.tif'\n",
      " '/home/rbbidart/project/rbbidart/cancer_hist/full_slides2/train/0/68_Region_1_crop.tif'\n",
      " '/home/rbbidart/project/rbbidart/cancer_hist/full_slides2/train/0/90_Region_11_crop.tif']\n",
      "[ '/home/rbbidart/project/rbbidart/cancer_hist/full_slides2/valid/0/46_Region_1_crop.tif'\n",
      " '/home/rbbidart/project/rbbidart/cancer_hist/full_slides2/valid/0/57_Region_77_crop.tif'\n",
      " '/home/rbbidart/project/rbbidart/cancer_hist/full_slides2/valid/0/65_Region_1_crop.tif'\n",
      " '/home/rbbidart/project/rbbidart/cancer_hist/full_slides2/valid/0/101_Region_8_crop.tif']\n"
     ]
    }
   ],
   "source": [
    "# Make sample dataset:\n",
    "def make_sample_unet(data_loc, out_loc, downsample_factor):\n",
    "    data_classes = glob.glob(data_loc+'/*')\n",
    "    for data_class_loc in data_classes:\n",
    "        imgs = glob.glob(data_class_loc+'/*')\n",
    "        imgs = [loc for loc in imgs if loc.rsplit('.', 1)[-1] in ['tif']]\n",
    "        data_class = data_class_loc.rsplit('/', 1)[1]\n",
    "        num = len(imgs)\n",
    "        sample_num = int(num/downsample_factor)\n",
    "        samp = np.random.choice(imgs, sample_num)\n",
    "        print(samp)\n",
    "        for file in samp:\n",
    "            name = file.rsplit('/', 1)[1]\n",
    "            new_loc = os.path.join(out_loc, data_class)\n",
    "            if not os.path.exists(new_loc):\n",
    "                os.makedirs(new_loc)\n",
    "            copyfile(file, os.path.join(new_loc , name))\n",
    "\n",
    "# data_loc = '/home/rbbidart/project/rbbidart/cancer_hist/full_slides2/train'\n",
    "# out_loc = '/home/rbbidart/project/rbbidart/cancer_hist/full_slides2_sample/train'\n",
    "# make_sample_unet(data_loc, out_loc, 5)\n",
    "\n",
    "# data_loc = '/home/rbbidart/project/rbbidart/cancer_hist/full_slides2/valid'\n",
    "# out_loc = '/home/rbbidart/project/rbbidart/cancer_hist/full_slides2_sample/valid'\n",
    "# make_sample_unet(data_loc, out_loc, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import glob\n",
    "from scipy.ndimage import rotate\n",
    "from PIL import Image\n",
    "\n",
    "import keras\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "from keras.engine.topology import Layer\n",
    "from keras import metrics\n",
    "from keras import layers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout, Flatten, Reshape, Input, concatenate, Conv2DTranspose\n",
    "from keras.layers.core import Activation, Dense, Lambda\n",
    "from keras.constraints import maxnorm\n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D, AveragePooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "\n",
    "\n",
    "############ DATA GENERATORS\n",
    "def data_gen_aug_combined(file_loc, mask_loc, batch_size, square_rot_p=.3, seed=101):\n",
    "    # square_rot_p is the prob of using a 90x rotation, otherwise sample from 360. Possibly not useful\n",
    "    # translate is maximum number of pixels to translate by\n",
    "    # crops are done \n",
    "    square_rot_p = int(square_rot_p)\n",
    "    np.random.seed(seed)\n",
    "    all_files=glob.glob(os.path.join(file_loc, '*'))\n",
    "    all_masks=[]\n",
    "\n",
    "    all_files = [loc for loc in all_files if loc.rsplit('.', 1)[-1] in ['tif']]\n",
    "\n",
    "#     for file in all_files:\n",
    "#         im_name = str(file.rsplit('.', 1)[-2].rsplit('/', 1)[1].rsplit('_', 1)[0].replace(\" \", \"_\"))\n",
    "#         loc = os.path.join(mask_loc, im_name+'.npy')\n",
    "#         all_masks.append(loc)\n",
    "        \n",
    "    for file in all_files:\n",
    "        im_name = str(file.rsplit('.', 1)[-2].rsplit('/', 1)[1])\n",
    "        loc = os.path.join(mask_loc, im_name+'.tif')\n",
    "        all_masks.append(loc)\n",
    "\n",
    "    while 1:\n",
    "        c = list(zip(all_files, all_masks))\n",
    "        np.random.shuffle(c)\n",
    "        all_files, all_masks = zip(*c)\n",
    "\n",
    "        num_batches = int(np.floor(len(all_files)/batch_size))-1\n",
    "\n",
    "        for batch in range(num_batches):\n",
    "            x=[]\n",
    "            y=[]\n",
    "            batch_files = all_files[batch_size*batch:batch_size*(batch+1)]\n",
    "            batch_files_mask = all_masks[batch_size*batch:batch_size*(batch+1)]\n",
    "\n",
    "            for index in range(len(batch_files)):\n",
    "                image_loc = batch_files[index]\n",
    "                mask_loc = batch_files_mask[index]\n",
    "\n",
    "                # load the image\n",
    "                image = Image.open(image_loc)\n",
    "                width, height = image.size\n",
    "                image = np.reshape(np.array(image.getdata()), (height, width, 3))\n",
    "\n",
    "                #load the mask\n",
    "                mask = Image.open(mask_loc)\n",
    "                width, height = mask.size\n",
    "                mask = np.reshape(np.array(mask.getdata()), (height, width, 4))\n",
    "                \n",
    "                # All the randomness:\n",
    "                height, width = np.shape(image)[0], np.shape(image)[1]\n",
    "                crop_row = np.random.randint(0, height-320)\n",
    "                crop_col = np.random.randint(0, width-368)\n",
    "                flip_vert = np.random.randint(0, 2)\n",
    "                flip_hor = np.random.randint(0, 2)\n",
    "\n",
    "                # APPLY AUGMENTATION:\n",
    "                # flips\n",
    "                if flip_vert:\n",
    "                    image = np.flipud(image)\n",
    "                    mask = np.flipud(mask)\n",
    "\n",
    "                if flip_hor:\n",
    "                    image = np.fliplr(image)\n",
    "                    mask = np.fliplr(mask)\n",
    "\n",
    "                # rotation\n",
    "                square_rot =  bool((np.random.uniform(0, 1, 1)<square_rot_p))\n",
    "                if square_rot:  # maybe this is dumb, but it cant hurt\n",
    "                    rotations=['0', '90', '180', '270']\n",
    "                    angle = int(random.choice(rotations))\n",
    "                    image = rotate(image, angle, reshape=False)\n",
    "                    mask = rotate(mask, angle, reshape=False)\n",
    "\n",
    "                else:\n",
    "                    angle = np.random.uniform(0, 360, 1)\n",
    "                    image = rotate(image, angle, reshape=False)\n",
    "                    mask = rotate(mask, angle, reshape=False)\n",
    " \n",
    "                # crop to 320 x 360 so it will fit into network, and for data augmentation\n",
    "                image = image[crop_row:crop_row+320, crop_col:crop_col+368]\n",
    "                mask = mask[crop_row:crop_row+320, crop_col:crop_col+368]\n",
    "\n",
    "                image = image/255.0 # make pixels in [0,1] \n",
    "                x.append(image)\n",
    "                y.append(mask)\n",
    "            x=np.array(x)\n",
    "            y=np.array(y)\n",
    "            yield (x, y)\n",
    "\n",
    "\n",
    "def data_gen_combined(file_loc, mask_loc, batch_size, seed=101):\n",
    "    np.random.seed(seed)\n",
    "    all_files=glob.glob(os.path.join(file_loc, '*'))\n",
    "    all_files = [loc for loc in all_files if loc.rsplit('.', 1)[-1] in ['tif']]\n",
    "    all_masks=[]\n",
    "    for file in all_files:\n",
    "        im_name = str(file.rsplit('.', 1)[-2].rsplit('/', 1)[1])\n",
    "        loc = os.path.join(mask_loc, im_name+'.tif')\n",
    "        all_masks.append(loc)\n",
    "\n",
    "    all_files = [loc for loc in all_files if loc.rsplit('.', 1)[-1] in ['tif']]\n",
    "\n",
    "    while 1:\n",
    "        c = list(zip(all_files, all_masks))\n",
    "        np.random.shuffle(c)\n",
    "        all_files, all_masks = zip(*c)\n",
    "        \n",
    "        num_batches = int(np.floor(len(all_files)/batch_size))-1\n",
    "        for batch in range(num_batches):\n",
    "            x=[]\n",
    "            y=[]\n",
    "            batch_files = all_files[batch_size*batch:batch_size*(batch+1)]\n",
    "            batch_files_mask = all_masks[batch_size*batch:batch_size*(batch+1)]\n",
    "\n",
    "            for index in range(len(batch_files)):\n",
    "                image_loc = batch_files[index]\n",
    "                mask_loc = batch_files_mask[index]\n",
    "\n",
    "                # load the image\n",
    "                image = Image.open(image_loc)\n",
    "                width, height = image.size\n",
    "                image = np.reshape(np.array(image.getdata()), (height, width, 3))\n",
    "\n",
    "                #load the mask\n",
    "                mask = Image.open(mask_loc)\n",
    "                width, height = mask.size\n",
    "                mask = np.reshape(np.array(mask.getdata()), (height, width, 4))\n",
    "                \n",
    "                ################################ IMPLEMENT::::\n",
    "                # We will pad the imput to make them all the same size:\n",
    "                \n",
    "                # make it the same size as the training examples\n",
    "                height, width = np.shape(image)[0], np.shape(image)[1]\n",
    "                crop_row = np.random.randint(0, height-320)\n",
    "                crop_col = np.random.randint(0, width-368)\n",
    "\n",
    "                # crop to 320 x 360 so it will fit into network, and for data augmentation\n",
    "                image = image[crop_row:crop_row+320, crop_col:crop_col+368]\n",
    "                mask = mask[crop_row:crop_row+320, crop_col:crop_col+368]\n",
    "\n",
    "                image = image/255.0 # make pixels in [0,1]     \n",
    "                x.append(image)\n",
    "                y.append(mask)\n",
    "\n",
    "            x=np.array(x)\n",
    "            y=np.array(y)\n",
    "            yield (x, y)\n",
    "\n",
    "\n",
    "\n",
    "# Distance loss function\n",
    "def distance_loss(y_true, y_pred):\n",
    "    weight = .05 # how mush does the distance matter compared to the cross entropy (fast ai used .001 for 4 more uncertain ones)\n",
    "    distance_loss = K.binary_crossentropy(y_pred[:, :, :, 0], y_true[:, :, :, 0])    \n",
    "    cross_entropy = K.categorical_crossentropy(y_true[:, :, :, 1:], y_pred[:, :, :, 1:])    \n",
    "\n",
    "    return(distance_loss*weight+(1-weight)*cross_entropy)\n",
    "\n",
    "\n",
    "def unet_mid2(learning_rate=.0001):\n",
    "    input_shape = (None, None, 3)\n",
    "    img_input = Input(shape=input_shape)\n",
    "    conv1 = conv_block(img_input, 32, 3, 3, dropout = .1, padding='same', strides=(1, 1), activation='relu')\n",
    "    conv1 = conv_block(conv1, 32, 3, 3, dropout = .1, padding='same', strides=(1, 1), activation='relu')\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "\n",
    "    conv2 = conv_block(pool1, 64, 3, 3, dropout = .1, padding='same', strides=(1, 1), activation='relu')\n",
    "    conv2 = conv_block(conv2, 64, 3, 3, dropout = .1, padding='same', strides=(1, 1), activation='relu')\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "\n",
    "    conv3 = conv_block(pool2, 128, 3, 3, dropout = .1, padding='same', strides=(1, 1), activation='relu')\n",
    "    conv3 = conv_block(conv3, 128, 3, 3, dropout = .1, padding='same', strides=(1, 1), activation='relu')\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "    pool4 = pool3\n",
    "    conv5 = conv_block(pool4, 256, 3, 3, dropout = .1, padding='same', strides=(1, 1), activation='relu')\n",
    "    conv5 = conv_block(conv5, 256, 3, 3, dropout = .1, padding='same', strides=(1, 1), activation='relu')\n",
    "\n",
    "    up6 = concatenate([Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(conv5), conv3], axis=3)\n",
    "    conv6 = conv_block(up6, 128, 3, 3, dropout = .1, padding='same', strides=(1, 1), activation='relu')\n",
    "    conv6 = conv_block(conv6, 128, 3, 3, dropout = .1, padding='same', strides=(1, 1), activation='relu')\n",
    "\n",
    "    up7 = concatenate([Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(conv6), conv2], axis=3)\n",
    "    conv7 = conv_block(up7, 64, 3, 3, dropout = .1, padding='same', strides=(1, 1), activation='relu')\n",
    "    conv7 = conv_block(conv7, 64, 3, 3, dropout = .1, padding='same', strides=(1, 1), activation='relu')\n",
    "\n",
    "    up8 = concatenate([Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(conv7), conv1], axis=3)\n",
    "    conv8 = conv_block(up8, 32, 3, 3, dropout = .1, padding='same', strides=(1, 1), activation='relu')\n",
    "    conv8 = conv_block(conv8, 32, 3, 3, dropout = .1, padding='same', strides=(1, 1), activation='relu')\n",
    "\n",
    "    conv9_dist = Conv2D(1, (1, 1), activation='sigmoid')(conv8)\n",
    "    conv9_cross_entropy = Conv2D(3, (1, 1), activation='softmax')(conv8)\n",
    "    output = concatenate([conv9_dist, conv9_cross_entropy])\n",
    "\n",
    "    model = Model(img_input, output)\n",
    "    model.compile(optimizer=Adam(lr=learning_rate), loss=distance_loss, metrics=[distance_loss])\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "def conv_block(x,\n",
    "              filters,\n",
    "              num_row,\n",
    "              num_col,\n",
    "              dropout, \n",
    "              padding='same',\n",
    "              strides=(1, 1),\n",
    "              activation='relu'):\n",
    "    x = Conv2D(filters, (num_row, num_col), strides=strides, padding=padding, activation=activation)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Dropout(dropout)(x)\n",
    "\n",
    "    x = Conv2D(filters, (num_row, num_col), strides=strides, padding=padding, activation=activation)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Dropout(dropout)(x)\n",
    "    return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/rbbidart/project/rbbidart/cancer_hist/full_slides2_sample/train/0\n",
      "/home/rbbidart/project/rbbidart/cancer_hist/full_slides2_sample/valid/0\n",
      "num_train 15\n",
      "num_valid 4\n",
      "validation_steps 2.0\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_5 (InputLayer)             (None, None, None, 3) 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_121 (Conv2D)              (None, None, None, 32 896         input_5[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_113 (BatchNo (None, None, None, 32 128         conv2d_121[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_113 (Activation)      (None, None, None, 32 0           batch_normalization_113[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "dropout_113 (Dropout)            (None, None, None, 32 0           activation_113[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_122 (Conv2D)              (None, None, None, 32 9248        dropout_113[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_114 (BatchNo (None, None, None, 32 128         conv2d_122[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_114 (Activation)      (None, None, None, 32 0           batch_normalization_114[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "dropout_114 (Dropout)            (None, None, None, 32 0           activation_114[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_123 (Conv2D)              (None, None, None, 32 9248        dropout_114[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_115 (BatchNo (None, None, None, 32 128         conv2d_123[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_115 (Activation)      (None, None, None, 32 0           batch_normalization_115[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "dropout_115 (Dropout)            (None, None, None, 32 0           activation_115[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_124 (Conv2D)              (None, None, None, 32 9248        dropout_115[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_116 (BatchNo (None, None, None, 32 128         conv2d_124[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_116 (Activation)      (None, None, None, 32 0           batch_normalization_116[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "dropout_116 (Dropout)            (None, None, None, 32 0           activation_116[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling2D)  (None, None, None, 32 0           dropout_116[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_125 (Conv2D)              (None, None, None, 64 18496       max_pooling2d_13[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_117 (BatchNo (None, None, None, 64 256         conv2d_125[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_117 (Activation)      (None, None, None, 64 0           batch_normalization_117[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "dropout_117 (Dropout)            (None, None, None, 64 0           activation_117[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_126 (Conv2D)              (None, None, None, 64 36928       dropout_117[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_118 (BatchNo (None, None, None, 64 256         conv2d_126[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_118 (Activation)      (None, None, None, 64 0           batch_normalization_118[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "dropout_118 (Dropout)            (None, None, None, 64 0           activation_118[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_127 (Conv2D)              (None, None, None, 64 36928       dropout_118[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_119 (BatchNo (None, None, None, 64 256         conv2d_127[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_119 (Activation)      (None, None, None, 64 0           batch_normalization_119[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "dropout_119 (Dropout)            (None, None, None, 64 0           activation_119[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_128 (Conv2D)              (None, None, None, 64 36928       dropout_119[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_120 (BatchNo (None, None, None, 64 256         conv2d_128[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_120 (Activation)      (None, None, None, 64 0           batch_normalization_120[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "dropout_120 (Dropout)            (None, None, None, 64 0           activation_120[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling2D)  (None, None, None, 64 0           dropout_120[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_129 (Conv2D)              (None, None, None, 12 73856       max_pooling2d_14[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_121 (BatchNo (None, None, None, 12 512         conv2d_129[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_121 (Activation)      (None, None, None, 12 0           batch_normalization_121[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "dropout_121 (Dropout)            (None, None, None, 12 0           activation_121[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_130 (Conv2D)              (None, None, None, 12 147584      dropout_121[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_122 (BatchNo (None, None, None, 12 512         conv2d_130[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_122 (Activation)      (None, None, None, 12 0           batch_normalization_122[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "dropout_122 (Dropout)            (None, None, None, 12 0           activation_122[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_131 (Conv2D)              (None, None, None, 12 147584      dropout_122[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_123 (BatchNo (None, None, None, 12 512         conv2d_131[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_123 (Activation)      (None, None, None, 12 0           batch_normalization_123[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "dropout_123 (Dropout)            (None, None, None, 12 0           activation_123[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_132 (Conv2D)              (None, None, None, 12 147584      dropout_123[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_124 (BatchNo (None, None, None, 12 512         conv2d_132[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_124 (Activation)      (None, None, None, 12 0           batch_normalization_124[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "dropout_124 (Dropout)            (None, None, None, 12 0           activation_124[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling2D)  (None, None, None, 12 0           dropout_124[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_133 (Conv2D)              (None, None, None, 25 295168      max_pooling2d_15[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_125 (BatchNo (None, None, None, 25 1024        conv2d_133[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_125 (Activation)      (None, None, None, 25 0           batch_normalization_125[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "dropout_125 (Dropout)            (None, None, None, 25 0           activation_125[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_134 (Conv2D)              (None, None, None, 25 590080      dropout_125[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_126 (BatchNo (None, None, None, 25 1024        conv2d_134[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_126 (Activation)      (None, None, None, 25 0           batch_normalization_126[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "dropout_126 (Dropout)            (None, None, None, 25 0           activation_126[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_135 (Conv2D)              (None, None, None, 25 590080      dropout_126[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_127 (BatchNo (None, None, None, 25 1024        conv2d_135[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_127 (Activation)      (None, None, None, 25 0           batch_normalization_127[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "dropout_127 (Dropout)            (None, None, None, 25 0           activation_127[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_136 (Conv2D)              (None, None, None, 25 590080      dropout_127[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_128 (BatchNo (None, None, None, 25 1024        conv2d_136[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_128 (Activation)      (None, None, None, 25 0           batch_normalization_128[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "dropout_128 (Dropout)            (None, None, None, 25 0           activation_128[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_transpose_13 (Conv2DTrans (None, None, None, 12 131200      dropout_128[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_17 (Concatenate)     (None, None, None, 25 0           conv2d_transpose_13[0][0]        \n",
      "                                                                   dropout_124[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_137 (Conv2D)              (None, None, None, 12 295040      concatenate_17[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_129 (BatchNo (None, None, None, 12 512         conv2d_137[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_129 (Activation)      (None, None, None, 12 0           batch_normalization_129[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "dropout_129 (Dropout)            (None, None, None, 12 0           activation_129[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_138 (Conv2D)              (None, None, None, 12 147584      dropout_129[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_130 (BatchNo (None, None, None, 12 512         conv2d_138[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_130 (Activation)      (None, None, None, 12 0           batch_normalization_130[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "dropout_130 (Dropout)            (None, None, None, 12 0           activation_130[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_139 (Conv2D)              (None, None, None, 12 147584      dropout_130[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_131 (BatchNo (None, None, None, 12 512         conv2d_139[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_131 (Activation)      (None, None, None, 12 0           batch_normalization_131[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "dropout_131 (Dropout)            (None, None, None, 12 0           activation_131[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_140 (Conv2D)              (None, None, None, 12 147584      dropout_131[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_132 (BatchNo (None, None, None, 12 512         conv2d_140[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_132 (Activation)      (None, None, None, 12 0           batch_normalization_132[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "dropout_132 (Dropout)            (None, None, None, 12 0           activation_132[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_transpose_14 (Conv2DTrans (None, None, None, 64 32832       dropout_132[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_18 (Concatenate)     (None, None, None, 12 0           conv2d_transpose_14[0][0]        \n",
      "                                                                   dropout_120[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_141 (Conv2D)              (None, None, None, 64 73792       concatenate_18[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_133 (BatchNo (None, None, None, 64 256         conv2d_141[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_133 (Activation)      (None, None, None, 64 0           batch_normalization_133[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "dropout_133 (Dropout)            (None, None, None, 64 0           activation_133[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_142 (Conv2D)              (None, None, None, 64 36928       dropout_133[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_134 (BatchNo (None, None, None, 64 256         conv2d_142[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_134 (Activation)      (None, None, None, 64 0           batch_normalization_134[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "dropout_134 (Dropout)            (None, None, None, 64 0           activation_134[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_143 (Conv2D)              (None, None, None, 64 36928       dropout_134[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_135 (BatchNo (None, None, None, 64 256         conv2d_143[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_135 (Activation)      (None, None, None, 64 0           batch_normalization_135[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "dropout_135 (Dropout)            (None, None, None, 64 0           activation_135[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_144 (Conv2D)              (None, None, None, 64 36928       dropout_135[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_136 (BatchNo (None, None, None, 64 256         conv2d_144[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_136 (Activation)      (None, None, None, 64 0           batch_normalization_136[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "dropout_136 (Dropout)            (None, None, None, 64 0           activation_136[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_transpose_15 (Conv2DTrans (None, None, None, 32 8224        dropout_136[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_19 (Concatenate)     (None, None, None, 64 0           conv2d_transpose_15[0][0]        \n",
      "                                                                   dropout_116[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_145 (Conv2D)              (None, None, None, 32 18464       concatenate_19[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_137 (BatchNo (None, None, None, 32 128         conv2d_145[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_137 (Activation)      (None, None, None, 32 0           batch_normalization_137[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "dropout_137 (Dropout)            (None, None, None, 32 0           activation_137[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_146 (Conv2D)              (None, None, None, 32 9248        dropout_137[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_138 (BatchNo (None, None, None, 32 128         conv2d_146[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_138 (Activation)      (None, None, None, 32 0           batch_normalization_138[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "dropout_138 (Dropout)            (None, None, None, 32 0           activation_138[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_147 (Conv2D)              (None, None, None, 32 9248        dropout_138[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_139 (BatchNo (None, None, None, 32 128         conv2d_147[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_139 (Activation)      (None, None, None, 32 0           batch_normalization_139[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "dropout_139 (Dropout)            (None, None, None, 32 0           activation_139[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_148 (Conv2D)              (None, None, None, 32 9248        dropout_139[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_140 (BatchNo (None, None, None, 32 128         conv2d_148[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_140 (Activation)      (None, None, None, 32 0           batch_normalization_140[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "dropout_140 (Dropout)            (None, None, None, 32 0           activation_140[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_149 (Conv2D)              (None, None, None, 1) 33          dropout_140[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_150 (Conv2D)              (None, None, None, 3) 99          dropout_140[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_20 (Concatenate)     (None, None, None, 4) 0           conv2d_149[0][0]                 \n",
      "                                                                   conv2d_150[0][0]                 \n",
      "====================================================================================================\n",
      "Total params: 3,892,164\n",
      "Trainable params: 3,886,532\n",
      "Non-trainable params: 5,632\n",
      "____________________________________________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "6/7 [========================>.....] - ETA: 7s - loss: 278.3297 - distance_loss: 278.3297 Epoch 00000: distance_loss improved from inf to 275.71064, saving model to /home/rbbidart/cancer_hist_out/unet_dist/sample/unet_mid2_custom_aug_.00-275.71.hdf5\n",
      "7/7 [==============================] - 83s - loss: 275.7106 - distance_loss: 275.7106 - val_loss: 266.5434 - val_distance_loss: 266.5433\n",
      "Epoch 2/50\n",
      "6/7 [========================>.....] - ETA: 0s - loss: 298.3763 - distance_loss: 298.3763Epoch 00001: distance_loss did not improve\n",
      "7/7 [==============================] - 9s - loss: 297.2719 - distance_loss: 297.2719 - val_loss: 266.4781 - val_distance_loss: 266.4779\n",
      "Epoch 3/50\n",
      "6/7 [========================>.....] - ETA: 0s - loss: 276.9791 - distance_loss: 276.9791Epoch 00002: distance_loss did not improve\n",
      "7/7 [==============================] - 14s - loss: 278.2212 - distance_loss: 278.2212 - val_loss: 266.3284 - val_distance_loss: 266.3285\n",
      "Epoch 4/50\n",
      "6/7 [========================>.....] - ETA: 2s - loss: 285.3409 - distance_loss: 285.3409Epoch 00003: distance_loss did not improve\n",
      "7/7 [==============================] - 27s - loss: 286.8394 - distance_loss: 286.8394 - val_loss: 266.2264 - val_distance_loss: 266.2264\n",
      "Epoch 5/50\n",
      "6/7 [========================>.....] - ETA: 2s - loss: 267.8284 - distance_loss: 267.8284Epoch 00004: distance_loss improved from 275.71064 to 264.90404, saving model to /home/rbbidart/cancer_hist_out/unet_dist/sample/unet_mid2_custom_aug_.04-264.90.hdf5\n",
      "7/7 [==============================] - 28s - loss: 264.9040 - distance_loss: 264.9040 - val_loss: 266.2497 - val_distance_loss: 266.2497\n",
      "Epoch 6/50\n",
      "6/7 [========================>.....] - ETA: 2s - loss: 268.3358 - distance_loss: 268.3358Epoch 00005: distance_loss did not improve\n",
      "7/7 [==============================] - 26s - loss: 267.5820 - distance_loss: 267.5820 - val_loss: 266.1510 - val_distance_loss: 266.1510\n",
      "Epoch 7/50\n",
      "6/7 [========================>.....] - ETA: 2s - loss: 264.8932 - distance_loss: 264.8932Epoch 00006: distance_loss improved from 264.90404 to 263.02095, saving model to /home/rbbidart/cancer_hist_out/unet_dist/sample/unet_mid2_custom_aug_.06-263.02.hdf5\n",
      "7/7 [==============================] - 28s - loss: 263.0210 - distance_loss: 263.0209 - val_loss: 266.0238 - val_distance_loss: 266.0239\n",
      "Epoch 8/50\n",
      "6/7 [========================>.....] - ETA: 2s - loss: 271.4113 - distance_loss: 271.4112Epoch 00007: distance_loss did not improve\n",
      "7/7 [==============================] - 25s - loss: 272.5471 - distance_loss: 272.5471 - val_loss: 265.8078 - val_distance_loss: 265.8079\n",
      "Epoch 9/50\n",
      "6/7 [========================>.....] - ETA: 2s - loss: 265.7019 - distance_loss: 265.7019Epoch 00008: distance_loss did not improve\n",
      "7/7 [==============================] - 26s - loss: 265.3211 - distance_loss: 265.3211 - val_loss: 265.6906 - val_distance_loss: 265.6907\n",
      "Epoch 10/50\n",
      "6/7 [========================>.....] - ETA: 2s - loss: 255.2214 - distance_loss: 255.2213Epoch 00009: distance_loss improved from 263.02095 to 260.39310, saving model to /home/rbbidart/cancer_hist_out/unet_dist/sample/unet_mid2_custom_aug_.09-260.39.hdf5\n",
      "7/7 [==============================] - 27s - loss: 260.3931 - distance_loss: 260.3931 - val_loss: 265.6937 - val_distance_loss: 265.6936\n",
      "Epoch 11/50\n",
      "6/7 [========================>.....] - ETA: 2s - loss: 263.2141 - distance_loss: 263.2141Epoch 00010: distance_loss did not improve\n",
      "7/7 [==============================] - 25s - loss: 263.3280 - distance_loss: 263.3280 - val_loss: 265.9615 - val_distance_loss: 265.9616\n",
      "Epoch 12/50\n",
      "6/7 [========================>.....] - ETA: 2s - loss: 265.0041 - distance_loss: 265.0041Epoch 00011: distance_loss did not improve\n",
      "7/7 [==============================] - 28s - loss: 264.8466 - distance_loss: 264.8466 - val_loss: 265.7354 - val_distance_loss: 265.7354\n",
      "Epoch 13/50\n",
      "6/7 [========================>.....] - ETA: 2s - loss: 243.9727 - distance_loss: 243.9728Epoch 00012: distance_loss improved from 260.39310 to 245.55282, saving model to /home/rbbidart/cancer_hist_out/unet_dist/sample/unet_mid2_custom_aug_.12-245.55.hdf5\n",
      "7/7 [==============================] - 26s - loss: 245.5528 - distance_loss: 245.5528 - val_loss: 265.6664 - val_distance_loss: 265.6663\n",
      "Epoch 14/50\n",
      "6/7 [========================>.....] - ETA: 2s - loss: 254.8764 - distance_loss: 254.8764Epoch 00013: distance_loss did not improve\n",
      "7/7 [==============================] - 24s - loss: 257.8346 - distance_loss: 257.8346 - val_loss: 265.6627 - val_distance_loss: 265.6627\n",
      "Epoch 15/50\n",
      "6/7 [========================>.....] - ETA: 3s - loss: 247.4565 - distance_loss: 247.4565Epoch 00014: distance_loss did not improve\n",
      "7/7 [==============================] - 27s - loss: 248.5016 - distance_loss: 248.5016 - val_loss: 265.3810 - val_distance_loss: 265.3810\n",
      "Epoch 16/50\n",
      "6/7 [========================>.....] - ETA: 2s - loss: 251.2969 - distance_loss: 251.2969Epoch 00015: distance_loss did not improve\n",
      "7/7 [==============================] - 25s - loss: 249.2203 - distance_loss: 249.2203 - val_loss: 264.9930 - val_distance_loss: 264.9928\n",
      "Epoch 17/50\n",
      "6/7 [========================>.....] - ETA: 2s - loss: 249.2623 - distance_loss: 249.2623Epoch 00016: distance_loss improved from 245.55282 to 244.33235, saving model to /home/rbbidart/cancer_hist_out/unet_dist/sample/unet_mid2_custom_aug_.16-244.33.hdf5\n",
      "7/7 [==============================] - 25s - loss: 244.3323 - distance_loss: 244.3324 - val_loss: 265.9585 - val_distance_loss: 265.9585\n",
      "Epoch 18/50\n",
      "6/7 [========================>.....] - ETA: 2s - loss: 254.1665 - distance_loss: 254.1665Epoch 00017: distance_loss did not improve\n",
      "7/7 [==============================] - 25s - loss: 250.7458 - distance_loss: 250.7458 - val_loss: 265.2564 - val_distance_loss: 265.2562\n",
      "Epoch 19/50\n",
      "6/7 [========================>.....] - ETA: 2s - loss: 256.0374 - distance_loss: 256.0373Epoch 00018: distance_loss did not improve\n",
      "7/7 [==============================] - 26s - loss: 252.6085 - distance_loss: 252.6085 - val_loss: 265.2107 - val_distance_loss: 265.2108\n",
      "Epoch 20/50\n",
      "6/7 [========================>.....] - ETA: 3s - loss: 259.7962 - distance_loss: 259.7962Epoch 00019: distance_loss did not improve\n",
      "7/7 [==============================] - 29s - loss: 260.5839 - distance_loss: 260.5839 - val_loss: 265.9220 - val_distance_loss: 265.9220\n",
      "Epoch 21/50\n",
      "6/7 [========================>.....] - ETA: 2s - loss: 247.4069 - distance_loss: 247.4069Epoch 00020: distance_loss did not improve\n",
      "7/7 [==============================] - 25s - loss: 245.8075 - distance_loss: 245.8075 - val_loss: 265.1726 - val_distance_loss: 265.1727\n",
      "Epoch 22/50\n",
      "6/7 [========================>.....] - ETA: 2s - loss: 247.4452 - distance_loss: 247.4453Epoch 00021: distance_loss did not improve\n",
      "7/7 [==============================] - 26s - loss: 248.3530 - distance_loss: 248.3530 - val_loss: 264.5768 - val_distance_loss: 264.5768\n",
      "Epoch 23/50\n",
      "6/7 [========================>.....] - ETA: 2s - loss: 247.3387 - distance_loss: 247.3387Epoch 00022: distance_loss improved from 244.33235 to 241.59153, saving model to /home/rbbidart/cancer_hist_out/unet_dist/sample/unet_mid2_custom_aug_.22-241.59.hdf5\n",
      "7/7 [==============================] - 26s - loss: 241.5915 - distance_loss: 241.5915 - val_loss: 265.2933 - val_distance_loss: 265.2933\n",
      "Epoch 24/50\n",
      "6/7 [========================>.....] - ETA: 2s - loss: 244.6695 - distance_loss: 244.6695Epoch 00023: distance_loss did not improve\n",
      "7/7 [==============================] - 25s - loss: 243.9669 - distance_loss: 243.9669 - val_loss: 264.2901 - val_distance_loss: 264.2902\n",
      "Epoch 25/50\n",
      "6/7 [========================>.....] - ETA: 2s - loss: 248.2328 - distance_loss: 248.2328Epoch 00024: distance_loss did not improve\n",
      "7/7 [==============================] - 26s - loss: 244.5646 - distance_loss: 244.5646 - val_loss: 264.0156 - val_distance_loss: 264.0154\n",
      "Epoch 26/50\n",
      "6/7 [========================>.....] - ETA: 2s - loss: 248.8246 - distance_loss: 248.8247Epoch 00025: distance_loss did not improve\n",
      "7/7 [==============================] - 26s - loss: 247.2697 - distance_loss: 247.2697 - val_loss: 264.1275 - val_distance_loss: 264.1273\n",
      "Epoch 27/50\n",
      "6/7 [========================>.....] - ETA: 2s - loss: 252.0177 - distance_loss: 252.0177Epoch 00026: distance_loss did not improve\n",
      "7/7 [==============================] - 24s - loss: 258.4869 - distance_loss: 258.4869 - val_loss: 265.2659 - val_distance_loss: 265.2659\n",
      "Epoch 28/50\n",
      "6/7 [========================>.....] - ETA: 2s - loss: 243.6067 - distance_loss: 243.6067Epoch 00027: distance_loss did not improve\n",
      "7/7 [==============================] - 25s - loss: 243.8918 - distance_loss: 243.8918 - val_loss: 264.5186 - val_distance_loss: 264.5185\n",
      "Epoch 29/50\n",
      "6/7 [========================>.....] - ETA: 3s - loss: 237.8228 - distance_loss: 237.8228Epoch 00028: distance_loss improved from 241.59153 to 238.93623, saving model to /home/rbbidart/cancer_hist_out/unet_dist/sample/unet_mid2_custom_aug_.28-238.94.hdf5\n",
      "7/7 [==============================] - 32s - loss: 238.9362 - distance_loss: 238.9362 - val_loss: 263.8732 - val_distance_loss: 263.8731\n",
      "Epoch 30/50\n",
      "6/7 [========================>.....] - ETA: 2s - loss: 242.6171 - distance_loss: 242.6171Epoch 00029: distance_loss did not improve\n",
      "7/7 [==============================] - 25s - loss: 239.8644 - distance_loss: 239.8644 - val_loss: 264.7794 - val_distance_loss: 264.7795\n",
      "Epoch 31/50\n",
      "6/7 [========================>.....] - ETA: 2s - loss: 224.6425 - distance_loss: 224.6425Epoch 00030: distance_loss improved from 238.93623 to 228.80337, saving model to /home/rbbidart/cancer_hist_out/unet_dist/sample/unet_mid2_custom_aug_.30-228.80.hdf5\n",
      "7/7 [==============================] - 27s - loss: 228.8034 - distance_loss: 228.8034 - val_loss: 263.9364 - val_distance_loss: 263.9363\n",
      "Epoch 32/50\n",
      "6/7 [========================>.....] - ETA: 2s - loss: 237.2918 - distance_loss: 237.2918Epoch 00031: distance_loss did not improve\n",
      "7/7 [==============================] - 23s - loss: 247.6899 - distance_loss: 247.6899 - val_loss: 265.1389 - val_distance_loss: 265.1389\n",
      "Epoch 33/50\n",
      "6/7 [========================>.....] - ETA: 2s - loss: 223.1425 - distance_loss: 223.1425Epoch 00032: distance_loss improved from 228.80337 to 225.97039, saving model to /home/rbbidart/cancer_hist_out/unet_dist/sample/unet_mid2_custom_aug_.32-225.97.hdf5\n",
      "7/7 [==============================] - 29s - loss: 225.9704 - distance_loss: 225.9704 - val_loss: 263.4389 - val_distance_loss: 263.4390\n",
      "Epoch 34/50\n",
      "6/7 [========================>.....] - ETA: 2s - loss: 232.3223 - distance_loss: 232.3223Epoch 00033: distance_loss did not improve\n",
      "7/7 [==============================] - 54s - loss: 231.2782 - distance_loss: 231.2782 - val_loss: 263.4436 - val_distance_loss: 263.4434\n",
      "Epoch 35/50\n",
      "6/7 [========================>.....] - ETA: 2s - loss: 247.5816 - distance_loss: 247.5816Epoch 00034: distance_loss did not improve\n",
      "7/7 [==============================] - 23s - loss: 242.3898 - distance_loss: 242.3898 - val_loss: 264.2710 - val_distance_loss: 264.2708\n",
      "Epoch 36/50\n",
      "6/7 [========================>.....] - ETA: 2s - loss: 246.6405 - distance_loss: 246.6405Epoch 00035: distance_loss did not improve\n",
      "7/7 [==============================] - 23s - loss: 242.6358 - distance_loss: 242.6358 - val_loss: 263.7189 - val_distance_loss: 263.7189\n",
      "Epoch 37/50\n",
      "6/7 [========================>.....] - ETA: 2s - loss: 223.4264 - distance_loss: 223.4264Epoch 00036: distance_loss did not improve\n",
      "7/7 [==============================] - 24s - loss: 229.3804 - distance_loss: 229.3804 - val_loss: 265.7733 - val_distance_loss: 265.7733\n",
      "Epoch 38/50\n",
      "6/7 [========================>.....] - ETA: 2s - loss: 244.5085 - distance_loss: 244.5085Epoch 00037: distance_loss did not improve\n",
      "7/7 [==============================] - 24s - loss: 241.9263 - distance_loss: 241.9263 - val_loss: 263.2914 - val_distance_loss: 263.2915\n",
      "Epoch 39/50\n",
      "6/7 [========================>.....] - ETA: 2s - loss: 246.3019 - distance_loss: 246.3019Epoch 00038: distance_loss did not improve\n",
      "7/7 [==============================] - 22s - loss: 246.0445 - distance_loss: 246.0445 - val_loss: 262.9014 - val_distance_loss: 262.9016\n",
      "Epoch 40/50\n",
      "6/7 [========================>.....] - ETA: 2s - loss: 223.7914 - distance_loss: 223.7914Epoch 00039: distance_loss improved from 225.97039 to 222.30147, saving model to /home/rbbidart/cancer_hist_out/unet_dist/sample/unet_mid2_custom_aug_.39-222.30.hdf5\n",
      "7/7 [==============================] - 23s - loss: 222.3015 - distance_loss: 222.3015 - val_loss: 265.0656 - val_distance_loss: 265.0656\n",
      "Epoch 41/50\n",
      "6/7 [========================>.....] - ETA: 2s - loss: 228.1537 - distance_loss: 228.1537Epoch 00040: distance_loss did not improve\n",
      "7/7 [==============================] - 22s - loss: 224.0616 - distance_loss: 224.0616 - val_loss: 264.4810 - val_distance_loss: 264.4810\n",
      "Epoch 42/50\n",
      "6/7 [========================>.....] - ETA: 2s - loss: 230.7528 - distance_loss: 230.7528Epoch 00041: distance_loss did not improve\n",
      "7/7 [==============================] - 23s - loss: 231.1932 - distance_loss: 231.1932 - val_loss: 262.9317 - val_distance_loss: 262.9318\n",
      "Epoch 43/50\n",
      "6/7 [========================>.....] - ETA: 2s - loss: 231.9076 - distance_loss: 231.9076Epoch 00042: distance_loss did not improve\n",
      "7/7 [==============================] - 25s - loss: 230.2233 - distance_loss: 230.2233 - val_loss: 262.9436 - val_distance_loss: 262.9438\n",
      "Epoch 44/50\n",
      "6/7 [========================>.....] - ETA: 2s - loss: 239.3030 - distance_loss: 239.3030Epoch 00043: distance_loss did not improve\n",
      "7/7 [==============================] - 23s - loss: 231.0208 - distance_loss: 231.0208 - val_loss: 265.4268 - val_distance_loss: 265.4268\n",
      "Epoch 45/50\n",
      "6/7 [========================>.....] - ETA: 2s - loss: 232.6330 - distance_loss: 232.6329Epoch 00044: distance_loss did not improve\n",
      "7/7 [==============================] - 24s - loss: 230.2992 - distance_loss: 230.2992 - val_loss: 264.2192 - val_distance_loss: 264.2191\n",
      "Epoch 46/50\n",
      "6/7 [========================>.....] - ETA: 2s - loss: 240.3354 - distance_loss: 240.3354Epoch 00045: distance_loss did not improve\n",
      "7/7 [==============================] - 21s - loss: 238.8799 - distance_loss: 238.8799 - val_loss: 263.7970 - val_distance_loss: 263.7970\n",
      "Epoch 47/50\n",
      "6/7 [========================>.....] - ETA: 2s - loss: 232.3713 - distance_loss: 232.3713Epoch 00046: distance_loss did not improve\n",
      "7/7 [==============================] - 23s - loss: 235.5843 - distance_loss: 235.5842 - val_loss: 263.6828 - val_distance_loss: 263.6827\n",
      "Epoch 48/50\n",
      "6/7 [========================>.....] - ETA: 2s - loss: 220.2117 - distance_loss: 220.2117Epoch 00047: distance_loss improved from 222.30147 to 215.20741, saving model to /home/rbbidart/cancer_hist_out/unet_dist/sample/unet_mid2_custom_aug_.47-215.21.hdf5\n",
      "7/7 [==============================] - 25s - loss: 215.2074 - distance_loss: 215.2074 - val_loss: 263.5002 - val_distance_loss: 263.5003\n",
      "Epoch 49/50\n",
      "6/7 [========================>.....] - ETA: 2s - loss: 246.3846 - distance_loss: 246.3846Epoch 00048: distance_loss did not improve\n",
      "7/7 [==============================] - 21s - loss: 245.0111 - distance_loss: 245.0112 - val_loss: 263.3897 - val_distance_loss: 263.3897\n",
      "Epoch 50/50\n",
      "6/7 [========================>.....] - ETA: 2s - loss: 220.9264 - distance_loss: 220.9264Epoch 00049: distance_loss did not improve\n",
      "7/7 [==============================] - 23s - loss: 231.8347 - distance_loss: 231.8347 - val_loss: 264.0708 - val_distance_loss: 264.0708\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import glob\n",
    "import random\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import keras\n",
    "import pickle\n",
    "from keras import backend as K\n",
    "from keras.engine.topology import Layer\n",
    "from keras.layers import Dropout, Flatten, Reshape, Input\n",
    "from keras.layers.core import Activation, Dense, Lambda\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "import tensorflow as tf\n",
    "\n",
    "data_loc = '/home/rbbidart/project/rbbidart/cancer_hist/full_slides2_sample'\n",
    "mask_loc = '/home/rbbidart/project/rbbidart/cancer_hist/im_dist_labels'\n",
    "out_loc = '/home/rbbidart/cancer_hist_out/unet_dist/sample'\n",
    "epochs = 50\n",
    "batch_size = 2\n",
    "model_str = 'unet_mid2'\n",
    "\n",
    "def distance_loss(y_true, y_pred):\n",
    "    weight = .05 # how mush does the distance matter compared to the cross entropy (fast ai used .001 for 4 more uncertain ones)\n",
    "    distance_loss = K.binary_crossentropy(y_pred[:, :, :, 0], y_true[:, :, :, 0])    \n",
    "    cross_entropy = K.categorical_crossentropy(y_true[:, :, :, 1:], y_pred[:, :, :, 1:]) \n",
    "    tf.Print(distance_loss, [tf.shape(distance_loss)], message=\"distance_loss\")\n",
    "    tf.Print(cross_entropy, [tf.shape(cross_entropy)], message=\"cross_entropy\")\n",
    "    return(distance_loss*weight+(1-weight)*cross_entropy)\n",
    "\n",
    "\n",
    "parameters = {\n",
    "'learning_rate': .0001    \n",
    "}\n",
    "\n",
    "\n",
    "epochs=int(epochs)\n",
    "batch_size=int(batch_size)\n",
    "\n",
    "\n",
    "# Locations\n",
    "train_loc = os.path.join(str(data_loc),'train', str(0))\n",
    "train_mask_loc = os.path.join(str(mask_loc),'train', str(0))\n",
    "print(train_loc)\n",
    "\n",
    "valid_loc = os.path.join(str(data_loc),'valid', str(0))\n",
    "valid_mask_loc = os.path.join(str(mask_loc),'valid', str(0))\n",
    "print(valid_loc)\n",
    "\n",
    "\n",
    "num_train = len(glob.glob(os.path.join(train_loc, '*')))\n",
    "num_valid = len(glob.glob(os.path.join(valid_loc, '*')))\n",
    "print('num_train', num_train)\n",
    "print('num_valid', num_valid)\n",
    "\n",
    "# Params for all models\n",
    "batch_size=int(batch_size)   # make this divisible by len(x_data)\n",
    "steps_per_epoch = np.floor(num_train/batch_size) # num of batches from generator at each epoch. (make it full train set)\n",
    "validation_steps = np.floor(num_valid/batch_size)# size of validation dataset divided by batch size\n",
    "print('validation_steps', validation_steps)\n",
    "\n",
    "# need a batch generator to augment the labels same as the train images\n",
    "valid_generator = data_gen_combined(valid_loc, valid_mask_loc, batch_size, seed=101)\n",
    "train_generator = data_gen_aug_combined(train_loc, train_mask_loc, batch_size, square_rot_p=.3,  seed=101)\n",
    "\n",
    "model = unet_mid2(**parameters)\n",
    "print(model.summary())\n",
    "name = model_str+'_'+'custom_aug'\n",
    "out_file=os.path.join(str(out_loc), name)\n",
    "checkpointer = ModelCheckpoint(filepath=os.path.join(out_loc, name+'_.{epoch:02d}-{distance_loss:.2f}.hdf5'), verbose=1, monitor='distance_loss', save_best_only=True)\n",
    "\n",
    "callbacks = [EarlyStopping(monitor='distance_loss', patience=15, verbose=0),\n",
    "    ModelCheckpoint(filepath=os.path.join(out_loc, name + '_.{epoch:02d}-{distance_loss:.2f}.hdf5'), \n",
    "        verbose=1, monitor='distance_loss', save_best_only=True)]\n",
    "\n",
    "hist = model.fit_generator(train_generator,\n",
    "                                  validation_data=valid_generator,\n",
    "                                  steps_per_epoch=steps_per_epoch, \n",
    "                                  epochs=epochs,\n",
    "                                  validation_steps=validation_steps,\n",
    "                                  callbacks=callbacks)\n",
    "pickle.dump(hist.history, open(out_file, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/rbbidart/project/rbbidart/cancer_hist/full_slides2_sample/train/0\n",
      "/home/rbbidart/project/rbbidart/cancer_hist/full_slides2_sample/valid/0\n",
      "num_train 15\n",
      "num_valid 4\n",
      "validation_steps 2.0\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_7 (InputLayer)             (None, None, None, 3) 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_181 (Conv2D)              (None, None, None, 32 896         input_7[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_169 (BatchNo (None, None, None, 32 128         conv2d_181[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_169 (Activation)      (None, None, None, 32 0           batch_normalization_169[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "dropout_169 (Dropout)            (None, None, None, 32 0           activation_169[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_182 (Conv2D)              (None, None, None, 32 9248        dropout_169[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_170 (BatchNo (None, None, None, 32 128         conv2d_182[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_170 (Activation)      (None, None, None, 32 0           batch_normalization_170[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "dropout_170 (Dropout)            (None, None, None, 32 0           activation_170[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_183 (Conv2D)              (None, None, None, 32 9248        dropout_170[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_171 (BatchNo (None, None, None, 32 128         conv2d_183[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_171 (Activation)      (None, None, None, 32 0           batch_normalization_171[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "dropout_171 (Dropout)            (None, None, None, 32 0           activation_171[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_184 (Conv2D)              (None, None, None, 32 9248        dropout_171[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_172 (BatchNo (None, None, None, 32 128         conv2d_184[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_172 (Activation)      (None, None, None, 32 0           batch_normalization_172[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "dropout_172 (Dropout)            (None, None, None, 32 0           activation_172[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_19 (MaxPooling2D)  (None, None, None, 32 0           dropout_172[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_185 (Conv2D)              (None, None, None, 64 18496       max_pooling2d_19[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_173 (BatchNo (None, None, None, 64 256         conv2d_185[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_173 (Activation)      (None, None, None, 64 0           batch_normalization_173[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "dropout_173 (Dropout)            (None, None, None, 64 0           activation_173[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_186 (Conv2D)              (None, None, None, 64 36928       dropout_173[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_174 (BatchNo (None, None, None, 64 256         conv2d_186[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_174 (Activation)      (None, None, None, 64 0           batch_normalization_174[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "dropout_174 (Dropout)            (None, None, None, 64 0           activation_174[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_187 (Conv2D)              (None, None, None, 64 36928       dropout_174[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_175 (BatchNo (None, None, None, 64 256         conv2d_187[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_175 (Activation)      (None, None, None, 64 0           batch_normalization_175[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "dropout_175 (Dropout)            (None, None, None, 64 0           activation_175[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_188 (Conv2D)              (None, None, None, 64 36928       dropout_175[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_176 (BatchNo (None, None, None, 64 256         conv2d_188[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_176 (Activation)      (None, None, None, 64 0           batch_normalization_176[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "dropout_176 (Dropout)            (None, None, None, 64 0           activation_176[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_20 (MaxPooling2D)  (None, None, None, 64 0           dropout_176[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_189 (Conv2D)              (None, None, None, 12 73856       max_pooling2d_20[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_177 (BatchNo (None, None, None, 12 512         conv2d_189[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_177 (Activation)      (None, None, None, 12 0           batch_normalization_177[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "dropout_177 (Dropout)            (None, None, None, 12 0           activation_177[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_190 (Conv2D)              (None, None, None, 12 147584      dropout_177[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_178 (BatchNo (None, None, None, 12 512         conv2d_190[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_178 (Activation)      (None, None, None, 12 0           batch_normalization_178[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "dropout_178 (Dropout)            (None, None, None, 12 0           activation_178[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_191 (Conv2D)              (None, None, None, 12 147584      dropout_178[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_179 (BatchNo (None, None, None, 12 512         conv2d_191[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_179 (Activation)      (None, None, None, 12 0           batch_normalization_179[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "dropout_179 (Dropout)            (None, None, None, 12 0           activation_179[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_192 (Conv2D)              (None, None, None, 12 147584      dropout_179[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_180 (BatchNo (None, None, None, 12 512         conv2d_192[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_180 (Activation)      (None, None, None, 12 0           batch_normalization_180[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "dropout_180 (Dropout)            (None, None, None, 12 0           activation_180[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_21 (MaxPooling2D)  (None, None, None, 12 0           dropout_180[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_193 (Conv2D)              (None, None, None, 25 295168      max_pooling2d_21[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_181 (BatchNo (None, None, None, 25 1024        conv2d_193[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_181 (Activation)      (None, None, None, 25 0           batch_normalization_181[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "dropout_181 (Dropout)            (None, None, None, 25 0           activation_181[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_194 (Conv2D)              (None, None, None, 25 590080      dropout_181[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_182 (BatchNo (None, None, None, 25 1024        conv2d_194[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_182 (Activation)      (None, None, None, 25 0           batch_normalization_182[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "dropout_182 (Dropout)            (None, None, None, 25 0           activation_182[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_195 (Conv2D)              (None, None, None, 25 590080      dropout_182[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_183 (BatchNo (None, None, None, 25 1024        conv2d_195[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_183 (Activation)      (None, None, None, 25 0           batch_normalization_183[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "dropout_183 (Dropout)            (None, None, None, 25 0           activation_183[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_196 (Conv2D)              (None, None, None, 25 590080      dropout_183[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_184 (BatchNo (None, None, None, 25 1024        conv2d_196[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_184 (Activation)      (None, None, None, 25 0           batch_normalization_184[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "dropout_184 (Dropout)            (None, None, None, 25 0           activation_184[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_transpose_19 (Conv2DTrans (None, None, None, 12 131200      dropout_184[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_25 (Concatenate)     (None, None, None, 25 0           conv2d_transpose_19[0][0]        \n",
      "                                                                   dropout_180[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_197 (Conv2D)              (None, None, None, 12 295040      concatenate_25[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_185 (BatchNo (None, None, None, 12 512         conv2d_197[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_185 (Activation)      (None, None, None, 12 0           batch_normalization_185[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "dropout_185 (Dropout)            (None, None, None, 12 0           activation_185[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_198 (Conv2D)              (None, None, None, 12 147584      dropout_185[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_186 (BatchNo (None, None, None, 12 512         conv2d_198[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_186 (Activation)      (None, None, None, 12 0           batch_normalization_186[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "dropout_186 (Dropout)            (None, None, None, 12 0           activation_186[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_199 (Conv2D)              (None, None, None, 12 147584      dropout_186[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_187 (BatchNo (None, None, None, 12 512         conv2d_199[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_187 (Activation)      (None, None, None, 12 0           batch_normalization_187[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "dropout_187 (Dropout)            (None, None, None, 12 0           activation_187[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_200 (Conv2D)              (None, None, None, 12 147584      dropout_187[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_188 (BatchNo (None, None, None, 12 512         conv2d_200[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_188 (Activation)      (None, None, None, 12 0           batch_normalization_188[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "dropout_188 (Dropout)            (None, None, None, 12 0           activation_188[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_transpose_20 (Conv2DTrans (None, None, None, 64 32832       dropout_188[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_26 (Concatenate)     (None, None, None, 12 0           conv2d_transpose_20[0][0]        \n",
      "                                                                   dropout_176[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_201 (Conv2D)              (None, None, None, 64 73792       concatenate_26[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_189 (BatchNo (None, None, None, 64 256         conv2d_201[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_189 (Activation)      (None, None, None, 64 0           batch_normalization_189[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "dropout_189 (Dropout)            (None, None, None, 64 0           activation_189[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_202 (Conv2D)              (None, None, None, 64 36928       dropout_189[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_190 (BatchNo (None, None, None, 64 256         conv2d_202[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_190 (Activation)      (None, None, None, 64 0           batch_normalization_190[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "dropout_190 (Dropout)            (None, None, None, 64 0           activation_190[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_203 (Conv2D)              (None, None, None, 64 36928       dropout_190[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_191 (BatchNo (None, None, None, 64 256         conv2d_203[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_191 (Activation)      (None, None, None, 64 0           batch_normalization_191[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "dropout_191 (Dropout)            (None, None, None, 64 0           activation_191[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_204 (Conv2D)              (None, None, None, 64 36928       dropout_191[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_192 (BatchNo (None, None, None, 64 256         conv2d_204[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_192 (Activation)      (None, None, None, 64 0           batch_normalization_192[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "dropout_192 (Dropout)            (None, None, None, 64 0           activation_192[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_transpose_21 (Conv2DTrans (None, None, None, 32 8224        dropout_192[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_27 (Concatenate)     (None, None, None, 64 0           conv2d_transpose_21[0][0]        \n",
      "                                                                   dropout_172[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_205 (Conv2D)              (None, None, None, 32 18464       concatenate_27[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_193 (BatchNo (None, None, None, 32 128         conv2d_205[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_193 (Activation)      (None, None, None, 32 0           batch_normalization_193[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "dropout_193 (Dropout)            (None, None, None, 32 0           activation_193[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_206 (Conv2D)              (None, None, None, 32 9248        dropout_193[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_194 (BatchNo (None, None, None, 32 128         conv2d_206[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_194 (Activation)      (None, None, None, 32 0           batch_normalization_194[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "dropout_194 (Dropout)            (None, None, None, 32 0           activation_194[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_207 (Conv2D)              (None, None, None, 32 9248        dropout_194[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_195 (BatchNo (None, None, None, 32 128         conv2d_207[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_195 (Activation)      (None, None, None, 32 0           batch_normalization_195[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "dropout_195 (Dropout)            (None, None, None, 32 0           activation_195[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_208 (Conv2D)              (None, None, None, 32 9248        dropout_195[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_196 (BatchNo (None, None, None, 32 128         conv2d_208[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_196 (Activation)      (None, None, None, 32 0           batch_normalization_196[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "dropout_196 (Dropout)            (None, None, None, 32 0           activation_196[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_209 (Conv2D)              (None, None, None, 1) 33          dropout_196[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_210 (Conv2D)              (None, None, None, 3) 99          dropout_196[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_28 (Concatenate)     (None, None, None, 4) 0           conv2d_209[0][0]                 \n",
      "                                                                   conv2d_210[0][0]                 \n",
      "====================================================================================================\n",
      "Total params: 3,892,164\n",
      "Trainable params: 3,886,532\n",
      "Non-trainable params: 5,632\n",
      "____________________________________________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "6/7 [========================>.....] - ETA: 8s - loss: 6.8616 - distance_loss: 6.8616 Epoch 00000: distance_loss improved from inf to 6.84513, saving model to /home/rbbidart/cancer_hist_out/unet_dist/sample/unet_mid2_custom_aug_.00-6.85.hdf5\n",
      "7/7 [==============================] - 92s - loss: 6.8451 - distance_loss: 6.8451 - val_loss: 7.9684 - val_distance_loss: 7.9684\n",
      "Epoch 2/50\n",
      "6/7 [========================>.....] - ETA: 0s - loss: 6.6203 - distance_loss: 6.6203Epoch 00001: distance_loss improved from 6.84513 to 6.59332, saving model to /home/rbbidart/cancer_hist_out/unet_dist/sample/unet_mid2_custom_aug_.01-6.59.hdf5\n",
      "7/7 [==============================] - 17s - loss: 6.5933 - distance_loss: 6.5933 - val_loss: 7.9657 - val_distance_loss: 7.9657\n",
      "Epoch 3/50\n",
      "6/7 [========================>.....] - ETA: 0s - loss: 6.3276 - distance_loss: 6.3276Epoch 00002: distance_loss improved from 6.59332 to 6.30011, saving model to /home/rbbidart/cancer_hist_out/unet_dist/sample/unet_mid2_custom_aug_.02-6.30.hdf5\n",
      "7/7 [==============================] - 15s - loss: 6.3001 - distance_loss: 6.3001 - val_loss: 7.9629 - val_distance_loss: 7.9629\n",
      "Epoch 4/50\n",
      "6/7 [========================>.....] - ETA: 0s - loss: 5.9124 - distance_loss: 5.9124Epoch 00003: distance_loss improved from 6.30011 to 5.87812, saving model to /home/rbbidart/cancer_hist_out/unet_dist/sample/unet_mid2_custom_aug_.03-5.88.hdf5\n",
      "7/7 [==============================] - 16s - loss: 5.8781 - distance_loss: 5.8781 - val_loss: 7.9602 - val_distance_loss: 7.9602\n",
      "Epoch 5/50\n",
      "6/7 [========================>.....] - ETA: 0s - loss: 5.5508 - distance_loss: 5.5508Epoch 00004: distance_loss improved from 5.87812 to 5.54181, saving model to /home/rbbidart/cancer_hist_out/unet_dist/sample/unet_mid2_custom_aug_.04-5.54.hdf5\n",
      "7/7 [==============================] - 14s - loss: 5.5418 - distance_loss: 5.5418 - val_loss: 7.9575 - val_distance_loss: 7.9575\n",
      "Epoch 6/50\n",
      "6/7 [========================>.....] - ETA: 0s - loss: 5.2294 - distance_loss: 5.2294Epoch 00005: distance_loss improved from 5.54181 to 5.21269, saving model to /home/rbbidart/cancer_hist_out/unet_dist/sample/unet_mid2_custom_aug_.05-5.21.hdf5\n",
      "7/7 [==============================] - 17s - loss: 5.2127 - distance_loss: 5.2127 - val_loss: 7.9549 - val_distance_loss: 7.9549\n",
      "Epoch 7/50\n",
      "6/7 [========================>.....] - ETA: 0s - loss: 4.8713 - distance_loss: 4.8713Epoch 00006: distance_loss improved from 5.21269 to 4.84766, saving model to /home/rbbidart/cancer_hist_out/unet_dist/sample/unet_mid2_custom_aug_.06-4.85.hdf5\n",
      "7/7 [==============================] - 16s - loss: 4.8477 - distance_loss: 4.8477 - val_loss: 7.9524 - val_distance_loss: 7.9524\n",
      "Epoch 8/50\n",
      "6/7 [========================>.....] - ETA: 0s - loss: 4.5642 - distance_loss: 4.5642Epoch 00007: distance_loss improved from 4.84766 to 4.52949, saving model to /home/rbbidart/cancer_hist_out/unet_dist/sample/unet_mid2_custom_aug_.07-4.53.hdf5\n",
      "7/7 [==============================] - 16s - loss: 4.5295 - distance_loss: 4.5295 - val_loss: 7.9499 - val_distance_loss: 7.9499\n",
      "Epoch 9/50\n",
      "6/7 [========================>.....] - ETA: 0s - loss: 4.2743 - distance_loss: 4.2743Epoch 00008: distance_loss improved from 4.52949 to 4.24822, saving model to /home/rbbidart/cancer_hist_out/unet_dist/sample/unet_mid2_custom_aug_.08-4.25.hdf5\n",
      "7/7 [==============================] - 15s - loss: 4.2482 - distance_loss: 4.2482 - val_loss: 7.9475 - val_distance_loss: 7.9475\n",
      "Epoch 10/50\n",
      "6/7 [========================>.....] - ETA: 0s - loss: 4.0160 - distance_loss: 4.0160Epoch 00009: distance_loss improved from 4.24822 to 4.00215, saving model to /home/rbbidart/cancer_hist_out/unet_dist/sample/unet_mid2_custom_aug_.09-4.00.hdf5\n",
      "7/7 [==============================] - 15s - loss: 4.0021 - distance_loss: 4.0021 - val_loss: 7.9452 - val_distance_loss: 7.9452\n",
      "Epoch 11/50\n",
      "6/7 [========================>.....] - ETA: 0s - loss: 3.8274 - distance_loss: 3.8274Epoch 00010: distance_loss improved from 4.00215 to 3.81944, saving model to /home/rbbidart/cancer_hist_out/unet_dist/sample/unet_mid2_custom_aug_.10-3.82.hdf5\n",
      "7/7 [==============================] - 15s - loss: 3.8194 - distance_loss: 3.8194 - val_loss: 7.9428 - val_distance_loss: 7.9428\n",
      "Epoch 12/50\n",
      "6/7 [========================>.....] - ETA: 0s - loss: 3.6753 - distance_loss: 3.6753Epoch 00011: distance_loss improved from 3.81944 to 3.66638, saving model to /home/rbbidart/cancer_hist_out/unet_dist/sample/unet_mid2_custom_aug_.11-3.67.hdf5\n",
      "7/7 [==============================] - 15s - loss: 3.6664 - distance_loss: 3.6664 - val_loss: 7.9405 - val_distance_loss: 7.9405\n",
      "Epoch 13/50\n",
      "6/7 [========================>.....] - ETA: 0s - loss: 3.5613 - distance_loss: 3.5613Epoch 00012: distance_loss improved from 3.66638 to 3.55545, saving model to /home/rbbidart/cancer_hist_out/unet_dist/sample/unet_mid2_custom_aug_.12-3.56.hdf5\n",
      "7/7 [==============================] - 15s - loss: 3.5555 - distance_loss: 3.5555 - val_loss: 7.9382 - val_distance_loss: 7.9382\n",
      "Epoch 14/50\n",
      "6/7 [========================>.....] - ETA: 0s - loss: 3.4451 - distance_loss: 3.4451Epoch 00013: distance_loss improved from 3.55545 to 3.43984, saving model to /home/rbbidart/cancer_hist_out/unet_dist/sample/unet_mid2_custom_aug_.13-3.44.hdf5\n",
      "7/7 [==============================] - 16s - loss: 3.4398 - distance_loss: 3.4398 - val_loss: 7.9359 - val_distance_loss: 7.9359\n",
      "Epoch 15/50\n",
      "6/7 [========================>.....] - ETA: 0s - loss: 3.3515 - distance_loss: 3.3515Epoch 00014: distance_loss improved from 3.43984 to 3.34790, saving model to /home/rbbidart/cancer_hist_out/unet_dist/sample/unet_mid2_custom_aug_.14-3.35.hdf5\n",
      "7/7 [==============================] - 15s - loss: 3.3479 - distance_loss: 3.3479 - val_loss: 7.9336 - val_distance_loss: 7.9336\n",
      "Epoch 16/50\n",
      "6/7 [========================>.....] - ETA: 0s - loss: 3.2736 - distance_loss: 3.2736Epoch 00015: distance_loss improved from 3.34790 to 3.26839, saving model to /home/rbbidart/cancer_hist_out/unet_dist/sample/unet_mid2_custom_aug_.15-3.27.hdf5\n",
      "7/7 [==============================] - 17s - loss: 3.2684 - distance_loss: 3.2684 - val_loss: 7.9313 - val_distance_loss: 7.9313\n",
      "Epoch 17/50\n",
      "6/7 [========================>.....] - ETA: 0s - loss: 3.2147 - distance_loss: 3.2147Epoch 00016: distance_loss improved from 3.26839 to 3.21173, saving model to /home/rbbidart/cancer_hist_out/unet_dist/sample/unet_mid2_custom_aug_.16-3.21.hdf5\n",
      "7/7 [==============================] - 14s - loss: 3.2117 - distance_loss: 3.2117 - val_loss: 7.9290 - val_distance_loss: 7.9290\n",
      "Epoch 18/50\n",
      "6/7 [========================>.....] - ETA: 0s - loss: 3.1528 - distance_loss: 3.1528Epoch 00017: distance_loss improved from 3.21173 to 3.14814, saving model to /home/rbbidart/cancer_hist_out/unet_dist/sample/unet_mid2_custom_aug_.17-3.15.hdf5\n",
      "7/7 [==============================] - 15s - loss: 3.1481 - distance_loss: 3.1481 - val_loss: 7.9268 - val_distance_loss: 7.9268\n",
      "Epoch 19/50\n",
      "6/7 [========================>.....] - ETA: 0s - loss: 3.1019 - distance_loss: 3.1019Epoch 00018: distance_loss improved from 3.14814 to 3.09692, saving model to /home/rbbidart/cancer_hist_out/unet_dist/sample/unet_mid2_custom_aug_.18-3.10.hdf5\n",
      "7/7 [==============================] - 16s - loss: 3.0969 - distance_loss: 3.0969 - val_loss: 7.9245 - val_distance_loss: 7.9245\n",
      "Epoch 20/50\n",
      "6/7 [========================>.....] - ETA: 0s - loss: 3.0551 - distance_loss: 3.0551Epoch 00019: distance_loss improved from 3.09692 to 3.05128, saving model to /home/rbbidart/cancer_hist_out/unet_dist/sample/unet_mid2_custom_aug_.19-3.05.hdf5\n",
      "7/7 [==============================] - 15s - loss: 3.0513 - distance_loss: 3.0513 - val_loss: 7.9222 - val_distance_loss: 7.9222\n",
      "Epoch 21/50\n",
      "6/7 [========================>.....] - ETA: 0s - loss: 3.0100 - distance_loss: 3.0100Epoch 00020: distance_loss improved from 3.05128 to 3.00648, saving model to /home/rbbidart/cancer_hist_out/unet_dist/sample/unet_mid2_custom_aug_.20-3.01.hdf5\n",
      "7/7 [==============================] - 15s - loss: 3.0065 - distance_loss: 3.0065 - val_loss: 7.9199 - val_distance_loss: 7.9199\n",
      "Epoch 22/50\n",
      "6/7 [========================>.....] - ETA: 0s - loss: 2.9652 - distance_loss: 2.9652Epoch 00021: distance_loss improved from 3.00648 to 2.96233, saving model to /home/rbbidart/cancer_hist_out/unet_dist/sample/unet_mid2_custom_aug_.21-2.96.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 16s - loss: 2.9623 - distance_loss: 2.9623 - val_loss: 7.9176 - val_distance_loss: 7.9176\n",
      "Epoch 23/50\n",
      "6/7 [========================>.....] - ETA: 0s - loss: 2.9256 - distance_loss: 2.9256Epoch 00022: distance_loss improved from 2.96233 to 2.92527, saving model to /home/rbbidart/cancer_hist_out/unet_dist/sample/unet_mid2_custom_aug_.22-2.93.hdf5\n",
      "7/7 [==============================] - 14s - loss: 2.9253 - distance_loss: 2.9253 - val_loss: 7.9153 - val_distance_loss: 7.9153\n",
      "Epoch 24/50\n",
      "6/7 [========================>.....] - ETA: 0s - loss: 2.8921 - distance_loss: 2.8921Epoch 00023: distance_loss improved from 2.92527 to 2.89133, saving model to /home/rbbidart/cancer_hist_out/unet_dist/sample/unet_mid2_custom_aug_.23-2.89.hdf5\n",
      "7/7 [==============================] - 15s - loss: 2.8913 - distance_loss: 2.8913 - val_loss: 7.9131 - val_distance_loss: 7.9131\n",
      "Epoch 25/50\n",
      "6/7 [========================>.....] - ETA: 0s - loss: 2.8588 - distance_loss: 2.8588Epoch 00024: distance_loss improved from 2.89133 to 2.85675, saving model to /home/rbbidart/cancer_hist_out/unet_dist/sample/unet_mid2_custom_aug_.24-2.86.hdf5\n",
      "7/7 [==============================] - 13s - loss: 2.8568 - distance_loss: 2.8568 - val_loss: 7.9108 - val_distance_loss: 7.9108\n",
      "Epoch 26/50\n",
      "6/7 [========================>.....] - ETA: 0s - loss: 2.8254 - distance_loss: 2.8254Epoch 00025: distance_loss improved from 2.85675 to 2.82276, saving model to /home/rbbidart/cancer_hist_out/unet_dist/sample/unet_mid2_custom_aug_.25-2.82.hdf5\n",
      "7/7 [==============================] - 16s - loss: 2.8228 - distance_loss: 2.8228 - val_loss: 7.9085 - val_distance_loss: 7.9085\n",
      "Epoch 27/50\n",
      "6/7 [========================>.....] - ETA: 0s - loss: 2.7919 - distance_loss: 2.7919Epoch 00026: distance_loss improved from 2.82276 to 2.78909, saving model to /home/rbbidart/cancer_hist_out/unet_dist/sample/unet_mid2_custom_aug_.26-2.79.hdf5\n",
      "7/7 [==============================] - 15s - loss: 2.7891 - distance_loss: 2.7891 - val_loss: 7.9062 - val_distance_loss: 7.9062\n",
      "Epoch 28/50\n",
      "6/7 [========================>.....] - ETA: 0s - loss: 2.7602 - distance_loss: 2.7602Epoch 00027: distance_loss improved from 2.78909 to 2.75841, saving model to /home/rbbidart/cancer_hist_out/unet_dist/sample/unet_mid2_custom_aug_.27-2.76.hdf5\n",
      "7/7 [==============================] - 16s - loss: 2.7584 - distance_loss: 2.7584 - val_loss: 7.9040 - val_distance_loss: 7.9040\n",
      "Epoch 29/50\n",
      "6/7 [========================>.....] - ETA: 0s - loss: 2.7268 - distance_loss: 2.7268Epoch 00028: distance_loss improved from 2.75841 to 2.72518, saving model to /home/rbbidart/cancer_hist_out/unet_dist/sample/unet_mid2_custom_aug_.28-2.73.hdf5\n",
      "7/7 [==============================] - 16s - loss: 2.7252 - distance_loss: 2.7252 - val_loss: 7.9017 - val_distance_loss: 7.9017\n",
      "Epoch 30/50\n",
      "6/7 [========================>.....] - ETA: 0s - loss: 2.6983 - distance_loss: 2.6983Epoch 00029: distance_loss improved from 2.72518 to 2.69755, saving model to /home/rbbidart/cancer_hist_out/unet_dist/sample/unet_mid2_custom_aug_.29-2.70.hdf5\n",
      "7/7 [==============================] - 13s - loss: 2.6975 - distance_loss: 2.6975 - val_loss: 7.8994 - val_distance_loss: 7.8994\n",
      "Epoch 31/50\n",
      "6/7 [========================>.....] - ETA: 0s - loss: 2.6715 - distance_loss: 2.6715Epoch 00030: distance_loss improved from 2.69755 to 2.66897, saving model to /home/rbbidart/cancer_hist_out/unet_dist/sample/unet_mid2_custom_aug_.30-2.67.hdf5\n",
      "7/7 [==============================] - 15s - loss: 2.6690 - distance_loss: 2.6690 - val_loss: 7.8972 - val_distance_loss: 7.8972\n",
      "Epoch 32/50\n",
      "6/7 [========================>.....] - ETA: 0s - loss: 2.6442 - distance_loss: 2.6442Epoch 00031: distance_loss improved from 2.66897 to 2.63885, saving model to /home/rbbidart/cancer_hist_out/unet_dist/sample/unet_mid2_custom_aug_.31-2.64.hdf5\n",
      "7/7 [==============================] - 14s - loss: 2.6389 - distance_loss: 2.6389 - val_loss: 7.8949 - val_distance_loss: 7.8949\n",
      "Epoch 33/50\n",
      "6/7 [========================>.....] - ETA: 0s - loss: 2.6142 - distance_loss: 2.6142Epoch 00032: distance_loss improved from 2.63885 to 2.61120, saving model to /home/rbbidart/cancer_hist_out/unet_dist/sample/unet_mid2_custom_aug_.32-2.61.hdf5\n",
      "7/7 [==============================] - 14s - loss: 2.6112 - distance_loss: 2.6112 - val_loss: 7.8926 - val_distance_loss: 7.8926\n",
      "Epoch 34/50\n",
      "6/7 [========================>.....] - ETA: 0s - loss: 2.5880 - distance_loss: 2.5880Epoch 00033: distance_loss improved from 2.61120 to 2.58610, saving model to /home/rbbidart/cancer_hist_out/unet_dist/sample/unet_mid2_custom_aug_.33-2.59.hdf5\n",
      "7/7 [==============================] - 14s - loss: 2.5861 - distance_loss: 2.5861 - val_loss: 7.8904 - val_distance_loss: 7.8904\n",
      "Epoch 35/50\n",
      "6/7 [========================>.....] - ETA: 0s - loss: 2.5585 - distance_loss: 2.5585Epoch 00034: distance_loss improved from 2.58610 to 2.55665, saving model to /home/rbbidart/cancer_hist_out/unet_dist/sample/unet_mid2_custom_aug_.34-2.56.hdf5\n",
      "7/7 [==============================] - 14s - loss: 2.5566 - distance_loss: 2.5566 - val_loss: 7.8881 - val_distance_loss: 7.8881\n",
      "Epoch 36/50\n",
      "6/7 [========================>.....] - ETA: 0s - loss: 2.5281 - distance_loss: 2.5281Epoch 00035: distance_loss improved from 2.55665 to 2.52753, saving model to /home/rbbidart/cancer_hist_out/unet_dist/sample/unet_mid2_custom_aug_.35-2.53.hdf5\n",
      "7/7 [==============================] - 14s - loss: 2.5275 - distance_loss: 2.5275 - val_loss: 7.8858 - val_distance_loss: 7.8858\n",
      "Epoch 37/50\n",
      "6/7 [========================>.....] - ETA: 0s - loss: 2.5106 - distance_loss: 2.5106Epoch 00036: distance_loss improved from 2.52753 to 2.50887, saving model to /home/rbbidart/cancer_hist_out/unet_dist/sample/unet_mid2_custom_aug_.36-2.51.hdf5\n",
      "7/7 [==============================] - 14s - loss: 2.5089 - distance_loss: 2.5089 - val_loss: 7.8836 - val_distance_loss: 7.8836\n",
      "Epoch 38/50\n",
      "6/7 [========================>.....] - ETA: 0s - loss: 2.4849 - distance_loss: 2.4849Epoch 00037: distance_loss improved from 2.50887 to 2.48208, saving model to /home/rbbidart/cancer_hist_out/unet_dist/sample/unet_mid2_custom_aug_.37-2.48.hdf5\n",
      "7/7 [==============================] - 14s - loss: 2.4821 - distance_loss: 2.4821 - val_loss: 7.8814 - val_distance_loss: 7.8814\n",
      "Epoch 39/50\n",
      "6/7 [========================>.....] - ETA: 0s - loss: 2.4593 - distance_loss: 2.4593Epoch 00038: distance_loss improved from 2.48208 to 2.45758, saving model to /home/rbbidart/cancer_hist_out/unet_dist/sample/unet_mid2_custom_aug_.38-2.46.hdf5\n",
      "7/7 [==============================] - 14s - loss: 2.4576 - distance_loss: 2.4576 - val_loss: 7.8791 - val_distance_loss: 7.8791\n",
      "Epoch 40/50\n",
      "6/7 [========================>.....] - ETA: 0s - loss: 2.4365 - distance_loss: 2.4365Epoch 00039: distance_loss improved from 2.45758 to 2.43584, saving model to /home/rbbidart/cancer_hist_out/unet_dist/sample/unet_mid2_custom_aug_.39-2.44.hdf5\n",
      "7/7 [==============================] - 15s - loss: 2.4358 - distance_loss: 2.4358 - val_loss: 7.8769 - val_distance_loss: 7.8769\n",
      "Epoch 41/50\n",
      "6/7 [========================>.....] - ETA: 0s - loss: 2.4108 - distance_loss: 2.4108Epoch 00040: distance_loss improved from 2.43584 to 2.40934, saving model to /home/rbbidart/cancer_hist_out/unet_dist/sample/unet_mid2_custom_aug_.40-2.41.hdf5\n",
      "7/7 [==============================] - 16s - loss: 2.4093 - distance_loss: 2.4093 - val_loss: 7.8747 - val_distance_loss: 7.8747\n",
      "Epoch 42/50\n",
      "6/7 [========================>.....] - ETA: 0s - loss: 2.3826 - distance_loss: 2.3826Epoch 00041: distance_loss improved from 2.40934 to 2.38216, saving model to /home/rbbidart/cancer_hist_out/unet_dist/sample/unet_mid2_custom_aug_.41-2.38.hdf5\n",
      "7/7 [==============================] - 15s - loss: 2.3822 - distance_loss: 2.3822 - val_loss: 7.8724 - val_distance_loss: 7.8724\n",
      "Epoch 43/50\n",
      "6/7 [========================>.....] - ETA: 0s - loss: 2.3632 - distance_loss: 2.3632Epoch 00042: distance_loss improved from 2.38216 to 2.36238, saving model to /home/rbbidart/cancer_hist_out/unet_dist/sample/unet_mid2_custom_aug_.42-2.36.hdf5\n",
      "7/7 [==============================] - 15s - loss: 2.3624 - distance_loss: 2.3624 - val_loss: 7.8702 - val_distance_loss: 7.8702\n",
      "Epoch 44/50\n",
      "6/7 [========================>.....] - ETA: 0s - loss: 2.3382 - distance_loss: 2.3382Epoch 00043: distance_loss improved from 2.36238 to 2.33685, saving model to /home/rbbidart/cancer_hist_out/unet_dist/sample/unet_mid2_custom_aug_.43-2.34.hdf5\n",
      "7/7 [==============================] - 14s - loss: 2.3369 - distance_loss: 2.3369 - val_loss: 7.8680 - val_distance_loss: 7.8680\n",
      "Epoch 45/50\n",
      "3/7 [===========>..................] - ETA: 1s - loss: 2.3219 - distance_loss: 2.3219Epoch 00047: distance_loss improved from 2.26315 to 2.24388, saving model to /home/rbbidart/cancer_hist_out/unet_dist/sample/unet_mid2_custom_aug_.47-2.24.hdf5\n",
      "7/7 [==============================] - 14s - loss: 2.2439 - distance_loss: 2.2439 - val_loss: 7.8592 - val_distance_loss: 7.8592\n",
      "Epoch 49/50\n",
      "6/7 [========================>.....] - ETA: 0s - loss: 2.2200 - distance_loss: 2.2200Epoch 00048: distance_loss improved from 2.24388 to 2.21885, saving model to /home/rbbidart/cancer_hist_out/unet_dist/sample/unet_mid2_custom_aug_.48-2.22.hdf5\n",
      "7/7 [==============================] - 13s - loss: 2.2188 - distance_loss: 2.2188 - val_loss: 7.8570 - val_distance_loss: 7.8569\n",
      "Epoch 50/50\n",
      "6/7 [========================>.....] - ETA: 0s - loss: 2.1958 - distance_loss: 2.1958Epoch 00049: distance_loss improved from 2.21885 to 2.19418, saving model to /home/rbbidart/cancer_hist_out/unet_dist/sample/unet_mid2_custom_aug_.49-2.19.hdf5\n",
      "7/7 [==============================] - 16s - loss: 2.1942 - distance_loss: 2.1942 - val_loss: 7.8548 - val_distance_loss: 7.8548\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import glob\n",
    "import random\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import keras\n",
    "import pickle\n",
    "from keras import backend as K\n",
    "from keras.engine.topology import Layer\n",
    "from keras.layers import Dropout, Flatten, Reshape, Input\n",
    "from keras.layers.core import Activation, Dense, Lambda\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "import tensorflow as tf\n",
    "\n",
    "data_loc = '/home/rbbidart/project/rbbidart/cancer_hist/full_slides2_sample'\n",
    "mask_loc = '/home/rbbidart/project/rbbidart/cancer_hist/im_dist_labels'\n",
    "out_loc = '/home/rbbidart/cancer_hist_out/unet_dist/sample'\n",
    "epochs = 50\n",
    "batch_size = 2\n",
    "model_str = 'unet_mid2'\n",
    "\n",
    "def distance_loss(y_true, y_pred):\n",
    "    weight = 1 # how mush does the distance matter compared to the cross entropy (fast ai used .001 for 4 more uncertain ones)\n",
    "    distance_loss = K.binary_crossentropy(y_pred[:, :, :, 0], y_true[:, :, :, 0])    \n",
    "    cross_entropy = K.categorical_crossentropy(y_true[:, :, :, 1:], y_pred[:, :, :, 1:]) \n",
    "    tf.Print(distance_loss, [tf.shape(distance_loss)], message=\"distance_loss\")\n",
    "    tf.Print(cross_entropy, [tf.shape(cross_entropy)], message=\"cross_entropy\")\n",
    "    return(distance_loss*weight+(1-weight)*cross_entropy)\n",
    "\n",
    "\n",
    "parameters = {\n",
    "'learning_rate': .0001    \n",
    "}\n",
    "\n",
    "\n",
    "epochs=int(epochs)\n",
    "batch_size=int(batch_size)\n",
    "\n",
    "\n",
    "# Locations\n",
    "train_loc = os.path.join(str(data_loc),'train', str(0))\n",
    "train_mask_loc = os.path.join(str(mask_loc),'train', str(0))\n",
    "print(train_loc)\n",
    "\n",
    "valid_loc = os.path.join(str(data_loc),'valid', str(0))\n",
    "valid_mask_loc = os.path.join(str(mask_loc),'valid', str(0))\n",
    "print(valid_loc)\n",
    "\n",
    "\n",
    "num_train = len(glob.glob(os.path.join(train_loc, '*')))\n",
    "num_valid = len(glob.glob(os.path.join(valid_loc, '*')))\n",
    "print('num_train', num_train)\n",
    "print('num_valid', num_valid)\n",
    "\n",
    "# Params for all models\n",
    "batch_size=int(batch_size)   # make this divisible by len(x_data)\n",
    "steps_per_epoch = np.floor(num_train/batch_size) # num of batches from generator at each epoch. (make it full train set)\n",
    "validation_steps = np.floor(num_valid/batch_size)# size of validation dataset divided by batch size\n",
    "print('validation_steps', validation_steps)\n",
    "\n",
    "# need a batch generator to augment the labels same as the train images\n",
    "valid_generator = data_gen_combined(valid_loc, valid_mask_loc, batch_size, seed=101)\n",
    "train_generator = data_gen_combined(train_loc, train_mask_loc, batch_size, seed=101)\n",
    "\n",
    "model = unet_mid2(**parameters)\n",
    "print(model.summary())\n",
    "name = model_str+'_'+'custom_aug'\n",
    "out_file=os.path.join(str(out_loc), name)\n",
    "checkpointer = ModelCheckpoint(filepath=os.path.join(out_loc, name+'_.{epoch:02d}-{distance_loss:.2f}.hdf5'), verbose=1, monitor='distance_loss', save_best_only=True)\n",
    "\n",
    "callbacks = [EarlyStopping(monitor='distance_loss', patience=15, verbose=0),\n",
    "    ModelCheckpoint(filepath=os.path.join(out_loc, name + '_.{epoch:02d}-{distance_loss:.2f}.hdf5'), \n",
    "        verbose=1, monitor='distance_loss', save_best_only=True)]\n",
    "\n",
    "hist = model.fit_generator(train_generator,\n",
    "                                  validation_data=valid_generator,\n",
    "                                  steps_per_epoch=steps_per_epoch, \n",
    "                                  epochs=epochs,\n",
    "                                  validation_steps=validation_steps,\n",
    "                                  callbacks=callbacks)\n",
    "pickle.dump(hist.history, open(out_file, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/rbbidart/project/rbbidart/cancer_hist/full_slides2_sample/train/0\n",
      "/home/rbbidart/project/rbbidart/cancer_hist/full_slides2_sample/valid/0\n",
      "num_train 15\n",
      "num_valid 4\n",
      "validation_steps 2.0\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_1 (InputLayer)             (None, None, None, 3) 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)                (None, None, None, 32 896         input_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNorm (None, None, None, 32 128         conv2d_1[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "activation_1 (Activation)        (None, None, None, 32 0           batch_normalization_1[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)              (None, None, None, 32 0           activation_1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)                (None, None, None, 32 9248        dropout_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNorm (None, None, None, 32 128         conv2d_2[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "activation_2 (Activation)        (None, None, None, 32 0           batch_normalization_2[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)              (None, None, None, 32 0           activation_2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)                (None, None, None, 32 9248        dropout_2[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNorm (None, None, None, 32 128         conv2d_3[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "activation_3 (Activation)        (None, None, None, 32 0           batch_normalization_3[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)              (None, None, None, 32 0           activation_3[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)                (None, None, None, 32 9248        dropout_3[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNorm (None, None, None, 32 128         conv2d_4[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "activation_4 (Activation)        (None, None, None, 32 0           batch_normalization_4[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)              (None, None, None, 32 0           activation_4[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)   (None, None, None, 32 0           dropout_4[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)                (None, None, None, 64 18496       max_pooling2d_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNorm (None, None, None, 64 256         conv2d_5[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "activation_5 (Activation)        (None, None, None, 64 0           batch_normalization_5[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)              (None, None, None, 64 0           activation_5[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)                (None, None, None, 64 36928       dropout_5[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNorm (None, None, None, 64 256         conv2d_6[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "activation_6 (Activation)        (None, None, None, 64 0           batch_normalization_6[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)              (None, None, None, 64 0           activation_6[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)                (None, None, None, 64 36928       dropout_6[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNorm (None, None, None, 64 256         conv2d_7[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "activation_7 (Activation)        (None, None, None, 64 0           batch_normalization_7[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)              (None, None, None, 64 0           activation_7[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)                (None, None, None, 64 36928       dropout_7[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNorm (None, None, None, 64 256         conv2d_8[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "activation_8 (Activation)        (None, None, None, 64 0           batch_normalization_8[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)              (None, None, None, 64 0           activation_8[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)   (None, None, None, 64 0           dropout_8[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)                (None, None, None, 12 73856       max_pooling2d_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNorm (None, None, None, 12 512         conv2d_9[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "activation_9 (Activation)        (None, None, None, 12 0           batch_normalization_9[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)              (None, None, None, 12 0           activation_9[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)               (None, None, None, 12 147584      dropout_9[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNor (None, None, None, 12 512         conv2d_10[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_10 (Activation)       (None, None, None, 12 0           batch_normalization_10[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)             (None, None, None, 12 0           activation_10[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)               (None, None, None, 12 147584      dropout_10[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNor (None, None, None, 12 512         conv2d_11[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_11 (Activation)       (None, None, None, 12 0           batch_normalization_11[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)             (None, None, None, 12 0           activation_11[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)               (None, None, None, 12 147584      dropout_11[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNor (None, None, None, 12 512         conv2d_12[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_12 (Activation)       (None, None, None, 12 0           batch_normalization_12[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)             (None, None, None, 12 0           activation_12[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)   (None, None, None, 12 0           dropout_12[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)               (None, None, None, 25 295168      max_pooling2d_3[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNor (None, None, None, 25 1024        conv2d_13[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_13 (Activation)       (None, None, None, 25 0           batch_normalization_13[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "dropout_13 (Dropout)             (None, None, None, 25 0           activation_13[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)               (None, None, None, 25 590080      dropout_13[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNor (None, None, None, 25 1024        conv2d_14[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_14 (Activation)       (None, None, None, 25 0           batch_normalization_14[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "dropout_14 (Dropout)             (None, None, None, 25 0           activation_14[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)               (None, None, None, 25 590080      dropout_14[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNor (None, None, None, 25 1024        conv2d_15[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_15 (Activation)       (None, None, None, 25 0           batch_normalization_15[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "dropout_15 (Dropout)             (None, None, None, 25 0           activation_15[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)               (None, None, None, 25 590080      dropout_15[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNor (None, None, None, 25 1024        conv2d_16[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_16 (Activation)       (None, None, None, 25 0           batch_normalization_16[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "dropout_16 (Dropout)             (None, None, None, 25 0           activation_16[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTransp (None, None, None, 12 131200      dropout_16[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)      (None, None, None, 25 0           conv2d_transpose_1[0][0]         \n",
      "                                                                   dropout_12[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)               (None, None, None, 12 295040      concatenate_1[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNor (None, None, None, 12 512         conv2d_17[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_17 (Activation)       (None, None, None, 12 0           batch_normalization_17[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "dropout_17 (Dropout)             (None, None, None, 12 0           activation_17[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)               (None, None, None, 12 147584      dropout_17[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNor (None, None, None, 12 512         conv2d_18[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_18 (Activation)       (None, None, None, 12 0           batch_normalization_18[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "dropout_18 (Dropout)             (None, None, None, 12 0           activation_18[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)               (None, None, None, 12 147584      dropout_18[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNor (None, None, None, 12 512         conv2d_19[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_19 (Activation)       (None, None, None, 12 0           batch_normalization_19[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "dropout_19 (Dropout)             (None, None, None, 12 0           activation_19[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)               (None, None, None, 12 147584      dropout_19[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNor (None, None, None, 12 512         conv2d_20[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_20 (Activation)       (None, None, None, 12 0           batch_normalization_20[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "dropout_20 (Dropout)             (None, None, None, 12 0           activation_20[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTransp (None, None, None, 64 32832       dropout_20[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)      (None, None, None, 12 0           conv2d_transpose_2[0][0]         \n",
      "                                                                   dropout_8[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)               (None, None, None, 64 73792       concatenate_2[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNor (None, None, None, 64 256         conv2d_21[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_21 (Activation)       (None, None, None, 64 0           batch_normalization_21[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "dropout_21 (Dropout)             (None, None, None, 64 0           activation_21[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)               (None, None, None, 64 36928       dropout_21[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNor (None, None, None, 64 256         conv2d_22[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_22 (Activation)       (None, None, None, 64 0           batch_normalization_22[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "dropout_22 (Dropout)             (None, None, None, 64 0           activation_22[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)               (None, None, None, 64 36928       dropout_22[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNor (None, None, None, 64 256         conv2d_23[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_23 (Activation)       (None, None, None, 64 0           batch_normalization_23[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "dropout_23 (Dropout)             (None, None, None, 64 0           activation_23[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)               (None, None, None, 64 36928       dropout_23[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNor (None, None, None, 64 256         conv2d_24[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_24 (Activation)       (None, None, None, 64 0           batch_normalization_24[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "dropout_24 (Dropout)             (None, None, None, 64 0           activation_24[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTransp (None, None, None, 32 8224        dropout_24[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)      (None, None, None, 64 0           conv2d_transpose_3[0][0]         \n",
      "                                                                   dropout_4[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)               (None, None, None, 32 18464       concatenate_3[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNor (None, None, None, 32 128         conv2d_25[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_25 (Activation)       (None, None, None, 32 0           batch_normalization_25[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "dropout_25 (Dropout)             (None, None, None, 32 0           activation_25[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)               (None, None, None, 32 9248        dropout_25[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNor (None, None, None, 32 128         conv2d_26[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_26 (Activation)       (None, None, None, 32 0           batch_normalization_26[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "dropout_26 (Dropout)             (None, None, None, 32 0           activation_26[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)               (None, None, None, 32 9248        dropout_26[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNor (None, None, None, 32 128         conv2d_27[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_27 (Activation)       (None, None, None, 32 0           batch_normalization_27[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "dropout_27 (Dropout)             (None, None, None, 32 0           activation_27[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)               (None, None, None, 32 9248        dropout_27[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNor (None, None, None, 32 128         conv2d_28[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_28 (Activation)       (None, None, None, 32 0           batch_normalization_28[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "dropout_28 (Dropout)             (None, None, None, 32 0           activation_28[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)               (None, None, None, 1) 33          dropout_28[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)               (None, None, None, 3) 99          dropout_28[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)      (None, None, None, 4) 0           conv2d_29[0][0]                  \n",
      "                                                                   conv2d_30[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 3,892,164\n",
      "Trainable params: 3,886,532\n",
      "Non-trainable params: 5,632\n",
      "____________________________________________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "6/7 [========================>.....] - ETA: 16s - loss: 325.8872 - distance_loss: 325.8872Epoch 00000: distance_loss improved from inf to 319.09192, saving model to /home/rbbidart/cancer_hist_out/unet_dist/sample/unet_mid2_custom_aug_.00-319.09.hdf5\n",
      "7/7 [==============================] - 110s - loss: 319.0919 - distance_loss: 319.0919 - val_loss: 252.9308 - val_distance_loss: 252.9308\n",
      "Epoch 2/50\n",
      "6/7 [========================>.....] - ETA: 0s - loss: 351.5177 - distance_loss: 351.5177Epoch 00001: distance_loss did not improve\n",
      "7/7 [==============================] - 10s - loss: 340.0228 - distance_loss: 340.0228 - val_loss: 252.9133 - val_distance_loss: 252.9134\n",
      "Epoch 3/50\n",
      "6/7 [========================>.....] - ETA: 0s - loss: 306.1627 - distance_loss: 306.1627Epoch 00002: distance_loss improved from 319.09192 to 309.85493, saving model to /home/rbbidart/cancer_hist_out/unet_dist/sample/unet_mid2_custom_aug_.02-309.85.hdf5\n",
      "7/7 [==============================] - 17s - loss: 309.8549 - distance_loss: 309.8549 - val_loss: 252.8654 - val_distance_loss: 252.8654\n",
      "Epoch 4/50\n",
      "6/7 [========================>.....] - ETA: 0s - loss: 280.7449 - distance_loss: 280.7449Epoch 00003: distance_loss improved from 309.85493 to 277.39404, saving model to /home/rbbidart/cancer_hist_out/unet_dist/sample/unet_mid2_custom_aug_.03-277.39.hdf5\n",
      "7/7 [==============================] - 14s - loss: 277.3941 - distance_loss: 277.3940 - val_loss: 252.8368 - val_distance_loss: 252.8369\n",
      "Epoch 5/50\n",
      "6/7 [========================>.....] - ETA: 0s - loss: 302.0647 - distance_loss: 302.0647Epoch 00004: distance_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 301.8259 - distance_loss: 301.8259 - val_loss: 252.7653 - val_distance_loss: 252.7654\n",
      "Epoch 6/50\n",
      "6/7 [========================>.....] - ETA: 0s - loss: 277.5198 - distance_loss: 277.5198Epoch 00005: distance_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 277.9617 - distance_loss: 277.9617 - val_loss: 252.7965 - val_distance_loss: 252.7967\n",
      "Epoch 7/50\n",
      "6/7 [========================>.....] - ETA: 0s - loss: 289.8314 - distance_loss: 289.8314Epoch 00006: distance_loss did not improve\n",
      "7/7 [==============================] - 12s - loss: 285.8532 - distance_loss: 285.8532 - val_loss: 252.6772 - val_distance_loss: 252.6772\n",
      "Epoch 8/50\n",
      "6/7 [========================>.....] - ETA: 0s - loss: 266.0057 - distance_loss: 266.0057Epoch 00007: distance_loss improved from 277.39404 to 265.01014, saving model to /home/rbbidart/cancer_hist_out/unet_dist/sample/unet_mid2_custom_aug_.07-265.01.hdf5\n",
      "7/7 [==============================] - 19s - loss: 265.0102 - distance_loss: 265.0101 - val_loss: 252.5733 - val_distance_loss: 252.5734\n",
      "Epoch 9/50\n",
      "6/7 [========================>.....] - ETA: 0s - loss: 273.5392 - distance_loss: 273.5392Epoch 00008: distance_loss did not improve\n",
      "7/7 [==============================] - 12s - loss: 271.3750 - distance_loss: 271.3750 - val_loss: 252.6616 - val_distance_loss: 252.6616\n",
      "Epoch 10/50\n",
      "6/7 [========================>.....] - ETA: 0s - loss: 259.8219 - distance_loss: 259.8219Epoch 00009: distance_loss improved from 265.01014 to 261.54106, saving model to /home/rbbidart/cancer_hist_out/unet_dist/sample/unet_mid2_custom_aug_.09-261.54.hdf5\n",
      "7/7 [==============================] - 17s - loss: 261.5411 - distance_loss: 261.5411 - val_loss: 252.4444 - val_distance_loss: 252.4444\n",
      "Epoch 11/50\n",
      "6/7 [========================>.....] - ETA: 0s - loss: 260.0377 - distance_loss: 260.0377Epoch 00010: distance_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 262.6756 - distance_loss: 262.6755 - val_loss: 252.3669 - val_distance_loss: 252.3670\n",
      "Epoch 12/50\n",
      "6/7 [========================>.....] - ETA: 0s - loss: 269.0646 - distance_loss: 269.0647Epoch 00011: distance_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 266.7611 - distance_loss: 266.7611 - val_loss: 252.1192 - val_distance_loss: 252.1193\n",
      "Epoch 13/50\n",
      "6/7 [========================>.....] - ETA: 0s - loss: 273.9357 - distance_loss: 273.9357Epoch 00012: distance_loss did not improve\n",
      "7/7 [==============================] - 14s - loss: 273.8075 - distance_loss: 273.8075 - val_loss: 252.2190 - val_distance_loss: 252.2188\n",
      "Epoch 14/50\n",
      "6/7 [========================>.....] - ETA: 0s - loss: 256.6683 - distance_loss: 256.6683Epoch 00013: distance_loss improved from 261.54106 to 256.01607, saving model to /home/rbbidart/cancer_hist_out/unet_dist/sample/unet_mid2_custom_aug_.13-256.02.hdf5\n",
      "7/7 [==============================] - 18s - loss: 256.0161 - distance_loss: 256.0161 - val_loss: 252.2292 - val_distance_loss: 252.2292\n",
      "Epoch 15/50\n",
      "6/7 [========================>.....] - ETA: 0s - loss: 266.6111 - distance_loss: 266.6111Epoch 00014: distance_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 260.0394 - distance_loss: 260.0394 - val_loss: 252.5533 - val_distance_loss: 252.5533\n",
      "Epoch 16/50\n",
      "6/7 [========================>.....] - ETA: 0s - loss: 252.1717 - distance_loss: 252.1717Epoch 00015: distance_loss improved from 256.01607 to 250.58502, saving model to /home/rbbidart/cancer_hist_out/unet_dist/sample/unet_mid2_custom_aug_.15-250.59.hdf5\n",
      "7/7 [==============================] - 17s - loss: 250.5850 - distance_loss: 250.5850 - val_loss: 252.3910 - val_distance_loss: 252.3910\n",
      "Epoch 17/50\n",
      "6/7 [========================>.....] - ETA: 0s - loss: 247.3730 - distance_loss: 247.3730Epoch 00016: distance_loss improved from 250.58502 to 249.74922, saving model to /home/rbbidart/cancer_hist_out/unet_dist/sample/unet_mid2_custom_aug_.16-249.75.hdf5\n",
      "7/7 [==============================] - 17s - loss: 249.7492 - distance_loss: 249.7492 - val_loss: 252.2154 - val_distance_loss: 252.2156\n",
      "Epoch 18/50\n",
      "6/7 [========================>.....] - ETA: 0s - loss: 238.7726 - distance_loss: 238.7725Epoch 00017: distance_loss improved from 249.74922 to 246.71258, saving model to /home/rbbidart/cancer_hist_out/unet_dist/sample/unet_mid2_custom_aug_.17-246.71.hdf5\n",
      "7/7 [==============================] - 15s - loss: 246.7126 - distance_loss: 246.7126 - val_loss: 252.2008 - val_distance_loss: 252.2008\n",
      "Epoch 19/50\n",
      "6/7 [========================>.....] - ETA: 0s - loss: 250.2314 - distance_loss: 250.2314Epoch 00018: distance_loss did not improve\n",
      "7/7 [==============================] - 12s - loss: 254.8468 - distance_loss: 254.8468 - val_loss: 251.6836 - val_distance_loss: 251.6836\n",
      "Epoch 20/50\n",
      "6/7 [========================>.....] - ETA: 0s - loss: 261.0173 - distance_loss: 261.0174Epoch 00019: distance_loss did not improve\n",
      "7/7 [==============================] - 13s - loss: 269.3226 - distance_loss: 269.3226 - val_loss: 252.1373 - val_distance_loss: 252.1374\n",
      "Epoch 21/50\n",
      "6/7 [========================>.....] - ETA: 0s - loss: 229.0328 - distance_loss: 229.0327Epoch 00020: distance_loss improved from 246.71258 to 226.42119, saving model to /home/rbbidart/cancer_hist_out/unet_dist/sample/unet_mid2_custom_aug_.20-226.42.hdf5\n",
      "7/7 [==============================] - 17s - loss: 226.4212 - distance_loss: 226.4212 - val_loss: 251.7650 - val_distance_loss: 251.7649\n",
      "Epoch 22/50\n",
      "6/7 [========================>.....] - ETA: 0s - loss: 247.6606 - distance_loss: 247.6606Epoch 00021: distance_loss did not improve\n",
      "7/7 [==============================] - 11s - loss: 248.2875 - distance_loss: 248.2875 - val_loss: 251.8267 - val_distance_loss: 251.8266\n",
      "Epoch 23/50\n",
      "6/7 [========================>.....] - ETA: 0s - loss: 252.2820 - distance_loss: 252.2820Epoch 00022: distance_loss did not improve\n",
      "7/7 [==============================] - 13s - loss: 246.4033 - distance_loss: 246.4033 - val_loss: 252.2235 - val_distance_loss: 252.2236\n",
      "Epoch 24/50\n",
      "6/7 [========================>.....] - ETA: 0s - loss: 244.5209 - distance_loss: 244.5209Epoch 00023: distance_loss did not improve\n",
      "7/7 [==============================] - 14s - loss: 245.9322 - distance_loss: 245.9322 - val_loss: 251.3779 - val_distance_loss: 251.3779\n",
      "Epoch 25/50\n",
      "6/7 [========================>.....] - ETA: 0s - loss: 239.2784 - distance_loss: 239.2785Epoch 00024: distance_loss did not improve\n",
      "7/7 [==============================] - 14s - loss: 249.6623 - distance_loss: 249.6623 - val_loss: 251.5057 - val_distance_loss: 251.5057\n",
      "Epoch 26/50\n",
      "6/7 [========================>.....] - ETA: 0s - loss: 238.5679 - distance_loss: 238.5678Epoch 00025: distance_loss did not improve\n",
      "7/7 [==============================] - 13s - loss: 247.2783 - distance_loss: 247.2783 - val_loss: 251.7699 - val_distance_loss: 251.7700\n",
      "Epoch 27/50\n",
      "6/7 [========================>.....] - ETA: 0s - loss: 223.4813 - distance_loss: 223.4813Epoch 00026: distance_loss did not improve\n",
      "7/7 [==============================] - 13s - loss: 235.7703 - distance_loss: 235.7703 - val_loss: 251.8310 - val_distance_loss: 251.8310\n",
      "Epoch 28/50\n",
      "6/7 [========================>.....] - ETA: 0s - loss: 241.4179 - distance_loss: 241.4179Epoch 00027: distance_loss did not improve\n",
      "7/7 [==============================] - 14s - loss: 238.7626 - distance_loss: 238.7627 - val_loss: 251.7992 - val_distance_loss: 251.7993\n",
      "Epoch 29/50\n",
      "6/7 [========================>.....] - ETA: 0s - loss: 255.0796 - distance_loss: 255.0796Epoch 00028: distance_loss did not improve\n",
      "7/7 [==============================] - 15s - loss: 251.1682 - distance_loss: 251.1682 - val_loss: 251.6221 - val_distance_loss: 251.6221\n",
      "Epoch 30/50\n",
      "6/7 [========================>.....] - ETA: 0s - loss: 238.7727 - distance_loss: 238.7727Epoch 00029: distance_loss did not improve\n",
      "7/7 [==============================] - 14s - loss: 248.2040 - distance_loss: 248.2040 - val_loss: 252.1336 - val_distance_loss: 252.1337\n",
      "Epoch 31/50\n",
      "6/7 [========================>.....] - ETA: 0s - loss: 236.6962 - distance_loss: 236.6962Epoch 00030: distance_loss did not improve\n",
      "7/7 [==============================] - 15s - loss: 245.7468 - distance_loss: 245.7468 - val_loss: 251.8985 - val_distance_loss: 251.8985\n",
      "Epoch 32/50\n",
      "6/7 [========================>.....] - ETA: 0s - loss: 232.6377 - distance_loss: 232.6377Epoch 00031: distance_loss did not improve\n",
      "7/7 [==============================] - 13s - loss: 232.0495 - distance_loss: 232.0495 - val_loss: 251.9731 - val_distance_loss: 251.9729\n",
      "Epoch 33/50\n",
      "6/7 [========================>.....] - ETA: 0s - loss: 246.7156 - distance_loss: 246.7156Epoch 00032: distance_loss did not improve\n",
      "7/7 [==============================] - 14s - loss: 239.6847 - distance_loss: 239.6847 - val_loss: 251.4085 - val_distance_loss: 251.4085\n",
      "Epoch 34/50\n",
      "6/7 [========================>.....] - ETA: 0s - loss: 248.8444 - distance_loss: 248.8444Epoch 00033: distance_loss did not improve\n",
      "7/7 [==============================] - 14s - loss: 249.6105 - distance_loss: 249.6105 - val_loss: 250.8160 - val_distance_loss: 250.8160\n",
      "Epoch 35/50\n",
      "6/7 [========================>.....] - ETA: 0s - loss: 250.4907 - distance_loss: 250.4907Epoch 00034: distance_loss did not improve\n",
      "7/7 [==============================] - 14s - loss: 259.6812 - distance_loss: 259.6812 - val_loss: 252.1003 - val_distance_loss: 252.1002\n",
      "Epoch 36/50\n",
      "6/7 [========================>.....] - ETA: 0s - loss: 230.2279 - distance_loss: 230.2279Epoch 00035: distance_loss did not improve\n",
      "7/7 [==============================] - 13s - loss: 229.3710 - distance_loss: 229.3710 - val_loss: 251.7102 - val_distance_loss: 251.7103\n",
      "Epoch 37/50\n",
      "6/7 [========================>.....] - ETA: 0s - loss: 232.3641 - distance_loss: 232.3641Epoch 00036: distance_loss did not improve\n",
      "7/7 [==============================] - 16s - loss: 228.1101 - distance_loss: 228.1102 - val_loss: 251.3167 - val_distance_loss: 251.3167\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import glob\n",
    "import random\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import keras\n",
    "import pickle\n",
    "from keras import backend as K\n",
    "from keras.engine.topology import Layer\n",
    "from keras.layers import Dropout, Flatten, Reshape, Input\n",
    "from keras.layers.core import Activation, Dense, Lambda\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "import tensorflow as tf\n",
    "\n",
    "data_loc = '/home/rbbidart/project/rbbidart/cancer_hist/full_slides2_sample'\n",
    "mask_loc = '/home/rbbidart/project/rbbidart/cancer_hist/im_dist_labels'\n",
    "out_loc = '/home/rbbidart/cancer_hist_out/unet_dist/sample'\n",
    "epochs = 50\n",
    "batch_size = 2\n",
    "model_str = 'unet_mid2'\n",
    "\n",
    "def distance_loss(y_true, y_pred):\n",
    "    weight = .1 # how mush does the distance matter compared to the cross entropy (fast ai used .001 for 4 more uncertain ones)\n",
    "    distance_loss = K.binary_crossentropy(y_pred[:, :, :, 0], y_true[:, :, :, 0])    \n",
    "    cross_entropy = K.categorical_crossentropy(y_true[:, :, :, 1:], y_pred[:, :, :, 1:]) \n",
    "    tf.Print(distance_loss, [tf.shape(distance_loss)], message=\"distance_loss\")\n",
    "    tf.Print(cross_entropy, [tf.shape(cross_entropy)], message=\"cross_entropy\")\n",
    "    return(distance_loss*weight+(1-weight)*cross_entropy)\n",
    "\n",
    "\n",
    "parameters = {\n",
    "'learning_rate': .0001    \n",
    "}\n",
    "\n",
    "\n",
    "epochs=int(epochs)\n",
    "batch_size=int(batch_size)\n",
    "\n",
    "\n",
    "# Locations\n",
    "train_loc = os.path.join(str(data_loc),'train', str(0))\n",
    "train_mask_loc = os.path.join(str(mask_loc),'train', str(0))\n",
    "print(train_loc)\n",
    "\n",
    "valid_loc = os.path.join(str(data_loc),'valid', str(0))\n",
    "valid_mask_loc = os.path.join(str(mask_loc),'valid', str(0))\n",
    "print(valid_loc)\n",
    "\n",
    "\n",
    "num_train = len(glob.glob(os.path.join(train_loc, '*')))\n",
    "num_valid = len(glob.glob(os.path.join(valid_loc, '*')))\n",
    "print('num_train', num_train)\n",
    "print('num_valid', num_valid)\n",
    "\n",
    "# Params for all models\n",
    "batch_size=int(batch_size)   # make this divisible by len(x_data)\n",
    "steps_per_epoch = np.floor(num_train/batch_size) # num of batches from generator at each epoch. (make it full train set)\n",
    "validation_steps = np.floor(num_valid/batch_size)# size of validation dataset divided by batch size\n",
    "print('validation_steps', validation_steps)\n",
    "\n",
    "# need a batch generator to augment the labels same as the train images\n",
    "valid_generator = data_gen_combined(valid_loc, valid_mask_loc, batch_size, seed=101)\n",
    "train_generator = data_gen_combined(train_loc, train_mask_loc, batch_size, seed=101)\n",
    "\n",
    "model = unet_mid2(**parameters)\n",
    "print(model.summary())\n",
    "name = model_str+'_'+'custom_aug'\n",
    "out_file=os.path.join(str(out_loc), name)\n",
    "checkpointer = ModelCheckpoint(filepath=os.path.join(out_loc, name+'_.{epoch:02d}-{distance_loss:.2f}.hdf5'), verbose=1, monitor='distance_loss', save_best_only=True)\n",
    "\n",
    "callbacks = [EarlyStopping(monitor='distance_loss', patience=15, verbose=0),\n",
    "    ModelCheckpoint(filepath=os.path.join(out_loc, name + '_.{epoch:02d}-{distance_loss:.2f}.hdf5'), \n",
    "        verbose=1, monitor='distance_loss', save_best_only=True)]\n",
    "\n",
    "hist = model.fit_generator(train_generator,\n",
    "                                  validation_data=valid_generator,\n",
    "                                  steps_per_epoch=steps_per_epoch, \n",
    "                                  epochs=epochs,\n",
    "                                  validation_steps=validation_steps,\n",
    "                                  callbacks=callbacks)\n",
    "pickle.dump(hist.history, open(out_file, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/rbbidart/project/rbbidart/cancer_hist/full_slides2_sample/train/0\n",
      "/home/rbbidart/project/rbbidart/cancer_hist/full_slides2_sample/valid/0\n",
      "num_train 15\n",
      "num_valid 4\n",
      "validation_steps 2.0\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'data_gen_combined' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-b50a60168d93>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;31m# need a batch generator to augment the labels same as the train images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m \u001b[0mvalid_generator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_gen_combined\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_loc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_mask_loc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m101\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0mtrain_generator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_gen_combined\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_mask_loc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m101\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data_gen_combined' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "import sys\n",
    "import os\n",
    "import glob\n",
    "import random\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import keras\n",
    "import pickle\n",
    "from keras import backend as K\n",
    "from keras.engine.topology import Layer\n",
    "from keras.layers import Dropout, Flatten, Reshape, Input\n",
    "from keras.layers.core import Activation, Dense, Lambda\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "import tensorflow as tf\n",
    "\n",
    "def unet_standard(learning_rate=.0001):\n",
    "    input_shape = (None, None, 3)\n",
    "    img_input = Input(shape=input_shape)\n",
    "    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(img_input)\n",
    "    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "\n",
    "    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(pool1)\n",
    "    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "\n",
    "    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(pool2)\n",
    "    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv3)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "\n",
    "    conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(pool3)\n",
    "    conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv4)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n",
    "\n",
    "    conv5 = Conv2D(512, (3, 3), activation='relu', padding='same')(pool4)\n",
    "    conv5 = Conv2D(512, (3, 3), activation='relu', padding='same')(conv5)\n",
    "\n",
    "    up6 = concatenate([Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(conv5), conv4], axis=3)\n",
    "    conv6 = Conv2D(256, (3, 3), activation='relu', padding='same')(up6)\n",
    "    conv6 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv6)\n",
    "\n",
    "    up7 = concatenate([Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(conv6), conv3], axis=3)\n",
    "    conv7 = Conv2D(128, (3, 3), activation='relu', padding='same')(up7)\n",
    "    conv7 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv7)\n",
    "\n",
    "    up8 = concatenate([Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(conv7), conv2], axis=3)\n",
    "    conv8 = Conv2D(64, (3, 3), activation='relu', padding='same')(up8)\n",
    "    conv8 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv8)\n",
    "\n",
    "    up9 = concatenate([Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(conv8), conv1], axis=3)\n",
    "    conv9 = Conv2D(32, (3, 3), activation='relu', padding='same')(up9)\n",
    "    conv9 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv9)\n",
    "\n",
    "    conv10 = Conv2D(4, (1, 1), activation='softmax')(conv9)\n",
    "\n",
    "    model = Model(img_input, conv10)\n",
    "    model.compile(optimizer=Adam(lr=learning_rate), loss=dice_coef_loss, metrics=[dice_coef])\n",
    "    return model\n",
    "\n",
    "data_loc = '/home/rbbidart/project/rbbidart/cancer_hist/full_slides2_sample'\n",
    "mask_loc = '/home/rbbidart/project/rbbidart/cancer_hist/im_dist_labels'\n",
    "out_loc = '/home/rbbidart/cancer_hist_out/unet_dist/sample'\n",
    "epochs = 50\n",
    "batch_size = 2\n",
    "model_str = 'unet_mid2'\n",
    "\n",
    "def distance_loss(y_true, y_pred):\n",
    "    weight = .1 # how mush does the distance matter compared to the cross entropy (fast ai used .001 for 4 more uncertain ones)\n",
    "    distance_loss = K.binary_crossentropy(y_pred[:, :, :, 0], y_true[:, :, :, 0])    \n",
    "    cross_entropy = K.categorical_crossentropy(y_true[:, :, :, 1:], y_pred[:, :, :, 1:]) \n",
    "    distance_loss_print = tf.Print(distance_loss, [tf.shape(distance_loss)], message=\"distance_loss\")\n",
    "    cross_entropy_print = tf.Print(cross_entropy, [tf.shape(cross_entropy)], message=\"cross_entropy\")\n",
    "    return(distance_loss*weight+(1-weight)*cross_entropy)\n",
    "\n",
    "\n",
    "parameters = {\n",
    "'learning_rate': .0001    \n",
    "}\n",
    "\n",
    "\n",
    "epochs=int(epochs)\n",
    "batch_size=int(batch_size)\n",
    "\n",
    "\n",
    "# Locations\n",
    "train_loc = os.path.join(str(data_loc),'train', str(0))\n",
    "train_mask_loc = os.path.join(str(mask_loc),'train', str(0))\n",
    "print(train_loc)\n",
    "\n",
    "valid_loc = os.path.join(str(data_loc),'valid', str(0))\n",
    "valid_mask_loc = os.path.join(str(mask_loc),'valid', str(0))\n",
    "print(valid_loc)\n",
    "\n",
    "\n",
    "num_train = len(glob.glob(os.path.join(train_loc, '*')))\n",
    "num_valid = len(glob.glob(os.path.join(valid_loc, '*')))\n",
    "print('num_train', num_train)\n",
    "print('num_valid', num_valid)\n",
    "\n",
    "# Params for all models\n",
    "batch_size=int(batch_size)   # make this divisible by len(x_data)\n",
    "steps_per_epoch = np.floor(num_train/batch_size) # num of batches from generator at each epoch. (make it full train set)\n",
    "validation_steps = np.floor(num_valid/batch_size)# size of validation dataset divided by batch size\n",
    "print('validation_steps', validation_steps)\n",
    "\n",
    "# need a batch generator to augment the labels same as the train images\n",
    "valid_generator = data_gen_combined(valid_loc, valid_mask_loc, batch_size, seed=101)\n",
    "train_generator = data_gen_combined(train_loc, train_mask_loc, batch_size, seed=101)\n",
    "\n",
    "model = unet_standard(**parameters)\n",
    "print(model.summary())\n",
    "name = model_str+'_'+'custom_aug'\n",
    "out_file=os.path.join(str(out_loc), name)\n",
    "checkpointer = ModelCheckpoint(filepath=os.path.join(out_loc, name+'_.{epoch:02d}-{distance_loss:.2f}.hdf5'), verbose=1, monitor='distance_loss', save_best_only=True)\n",
    "\n",
    "callbacks = [EarlyStopping(monitor='distance_loss', patience=15, verbose=0),\n",
    "    ModelCheckpoint(filepath=os.path.join(out_loc, name + '_.{epoch:02d}-{distance_loss:.2f}.hdf5'), \n",
    "        verbose=1, monitor='distance_loss', save_best_only=True)]\n",
    "\n",
    "hist = model.fit_generator(train_generator,\n",
    "                                  validation_data=valid_generator,\n",
    "                                  steps_per_epoch=steps_per_epoch, \n",
    "                                  epochs=epochs,\n",
    "                                  validation_steps=validation_steps,\n",
    "                                  callbacks=callbacks)\n",
    "pickle.dump(hist.history, open(out_file, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
