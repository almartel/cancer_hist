{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lymphocyte localization\n",
    "Using the data set from http://www.andrewjanowczyk.com/deep-learning/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import glob\n",
    "import scipy.misc\n",
    "import matplotlib.pyplot as plt \n",
    "from matplotlib.pyplot import imshow\n",
    "from PIL import Image\n",
    "from numpy import linalg as LA\n",
    "from numpy.random import choice\n",
    "% matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Datasets\n",
    "* For positive class, randomly sample points of sdistance less than 2 from the center.\n",
    "* For negative class, randomly sample the hard areas for classification, and use random samples.\n",
    "* Hard areas are defined as where the previous classifier performed poorly ( high probability, but dist > 5?6?) from the center. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_heatmap_L(image_loc, model, height, downsample):\n",
    "    def softmax(x):\n",
    "        e_x = np.exp(x - np.max(x))\n",
    "        return e_x / e_x.sum()\n",
    "    image = np.asarray(Image.open(image_loc))[:,:,:3]\n",
    "    image_shape = image.shape\n",
    "    image = image/255.0 # During training the images were normalized\n",
    "    height = int(height)\n",
    "\n",
    "    last = model.layers[-2].output\n",
    "    model = Model(model.input, last)\n",
    "\n",
    "    out_shape = np.ceil(np.array(image.shape)/float(downsample)).astype(int)\n",
    "    out_shape[2] = 2 # there are 2 classes\n",
    "\n",
    "    delta=int((height)/2)\n",
    "    image = np.lib.pad(image, ((delta, delta-int(downsample)), (delta, delta-int(downsample)), (0,0)), 'constant', constant_values=(0, 0))\n",
    "    image = np.expand_dims(image, axis=0)\n",
    "    heat = model.predict(image, batch_size=1, verbose=0)\n",
    "    heat = np.reshape(heat, out_shape)\n",
    "    # now apply the softmax to only the 3 classes(not the overall class probability (why??))\n",
    "    heat[:,:,:] = np.apply_along_axis(softmax, 2, heat[:,:,:])\n",
    "    return heat[:,:,1]\n",
    "\n",
    "def extract_regions(data_loc, label_loc, out_dir, im_size, model, min_dist=3, samples_needed=400):\n",
    "    # Num pos samples = 4 * actual number. (120ish)\n",
    "    # sample the same number randomly, and from the hard class.(200 each)\n",
    "    num_per_point=4\n",
    "    elements = [-2, -1, 0, 1, 2] \n",
    "    weights = [0.1, 0.2, 0.4, 0.2, 0.1]\n",
    "    \n",
    "    im_size=int(im_size)\n",
    "\n",
    "    all_locs = glob.glob(os.path.join(data_loc, '*'))\n",
    "    folder_size = len(all_locs)\n",
    "    print('folder_size: ', folder_size)\n",
    "    \n",
    "    all_labels=glob.glob(os.path.join(label_loc, '*'))\n",
    "    all_labels = [loc for loc in all_labels if loc.rsplit('.', 1)[0][-1] == 'm']\n",
    "\n",
    "    for image_file in all_locs:\n",
    "        image = np.array(Image.open(image_file))[:,:,:3]\n",
    "        \n",
    "        # pad the image so you can always take the proper sized image\n",
    "        delta=int((im_size)/2)+3\n",
    "        image = np.lib.pad(image, ((delta, delta), (delta, delta), (0,0)), 'constant', constant_values=(0, 0))\n",
    "        \n",
    "        # get the labels. Find matching label image, and extract the coordinates:\n",
    "        img_num = image_file.rsplit('/', 1)[1].rsplit('.',1)[0][2:]\n",
    "        label_loc = next(loc for loc in all_labels if loc.rsplit('/', 1)[1].rsplit('.',1)[0][:-1]==img_num)\n",
    "\n",
    "        label_img = np.asarray(Image.open(label_loc))\n",
    "        label_list = np.asarray(np.where(label_img[:, :, 3]==255))\n",
    "        label_list = np.transpose(label_list)\n",
    "        label_list = label_list+delta\n",
    "\n",
    "        # Get the positive samples:\n",
    "        num_pos = 0\n",
    "        for point in label_list:\n",
    "            for i in range(num_per_point):\n",
    "                y = point[0] + np.random.choice(elements, p=weights)\n",
    "                x = point[1] + np.random.choice(elements, p=weights)\n",
    "                seg_image = image[y-delta+3:y+delta-3, x-delta+3:x+delta-3,:]\n",
    "\n",
    "                out_name=str(1)+'_'+str(num_pos)+'_'+img_num+'.jpg'\n",
    "                outfile=os.path.join(out_dir, out_name)\n",
    "                scipy.misc.imsave(outfile, seg_image)\n",
    "                num_pos = num_pos+1\n",
    "\n",
    "        # evenly sample the negatives from every image:\n",
    "        samp_taken = 0\n",
    "        while(samp_taken < samples_needed/2):\n",
    "            row = random.randint(delta, image.shape[0]-delta)\n",
    "            col = random.randint(delta, image.shape[1]-delta)\n",
    "            proposed_center = np.array([row, col])\n",
    "            dists = np.sqrt(np.sum((label_list - proposed_center) ** 2, axis=1))\n",
    "            min_ind = np.argmin(dists)\n",
    "            if (dists[min_ind] > min_dist+.5):\n",
    "                seg_image = image[row-delta:row+delta, col-delta:col+delta,:]\n",
    "                out_name=str(0)+'_'+str(samp_taken)+'_'+img_num+'.jpg'\n",
    "                outfile=os.path.join(out_dir, out_name)\n",
    "                scipy.misc.imsave(outfile, seg_image)\n",
    "                samp_taken=samp_taken+1\n",
    "                \n",
    "        # Sample from the hard locations:\n",
    "        heatmap = create_heatmap_L(image_file, model=model, height=im_size, downsample=2)\n",
    "        # upsample to make everything easier\n",
    "        heatmap = scipy.misc.imresize(heatmap, (100, 100))\n",
    "\n",
    "        # Remove the true points\n",
    "        heatmap = np.lib.pad(heatmap, ((3, 3), (3, 3)), 'constant', constant_values=(0, 0))\n",
    "        label_list = label_list-delta + 3 # change it back to the actual points\n",
    "\n",
    "        for point in label_list:\n",
    "            for row in range(-1*min_dist, min_dist+1, 1):\n",
    "                for col in range(-1*min_dist, min_dist+1, 1):\n",
    "                    # dont't just do a square\n",
    "                    dist = np.sqrt(row** 2 + col** 2)\n",
    "                    if (dist<=min_dist+.5):\n",
    "                        try:\n",
    "                            # classifier predicted top left point, so by adding 1 this centers it a bit better\n",
    "                            heatmap[int(point[0]+row+1), int(point[1]+col+1)] = 0 \n",
    "                        except Exception:\n",
    "                            continue\n",
    "        heatmap = heatmap[3:-3, 3:-3]\n",
    "                        \n",
    "        # get the top samples_needed points, sample samples_needed/2 of them\n",
    "        sample_point_list = np.unravel_index(np.argsort(heatmap.ravel())[-int(samples_needed):], heatmap.shape)\n",
    "        sample_point_list = np.transpose(np.asarray(sample_point_list))\n",
    "        idx = np.random.choice(len(sample_point_list), int(samples_needed/2))\n",
    "        sample_point_list = sample_point_list[idx]\n",
    "\n",
    "        for point in sample_point_list:\n",
    "            y = point[0] + delta\n",
    "            x = point[1] + delta\n",
    "            seg_image = image[y-delta:y+delta, x-delta:x+delta,:]\n",
    "\n",
    "            out_name=str(0)+'_'+str(num_pos)+'_'+img_num+'.jpg'\n",
    "            outfile=os.path.join(out_dir, out_name)\n",
    "            scipy.misc.imsave(outfile, seg_image)\n",
    "            num_pos = num_pos+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder_size:  20\n",
      "folder_size:  65\n",
      "folder_size:  15\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import load_model, Model\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '/Users/rb/Google_Drive/Waterloo/projects/cancer_hist/src')\n",
    "from functions import*\n",
    "from heat_models import*\n",
    "\n",
    "in_dir='/Users/rb/Documents/waterloo/projects/cancer_hist/lymphocyte/ttv_split/'\n",
    "label_loc='/Users/rb/Documents/waterloo/projects/cancer_hist/lymphocyte/manual_seg/center/'\n",
    "out_dir='/Users/rb/Documents/waterloo/projects/cancer_hist/lymphocyte/extracted_new_32'\n",
    "\n",
    "# model_loc='/Users/rb/Google_Drive/Waterloo/projects/cancer_hist/output/lymphocyte/conv_incp3_l/conv_incp3_64_.41-0.97.hdf5'\n",
    "model_loc='/Users/rb/Google_Drive/Waterloo/projects/cancer_hist/output/lymphocyte/conv_incp3_l_32/conv_incp3_32_.20-0.96.hdf5'\n",
    "\n",
    "model = conv_incp3(im_size=32)\n",
    "model.load_weights(model_loc)\n",
    "\n",
    "# First make the folders:\n",
    "train_dir_in=os.path.join(in_dir, \"train\")\n",
    "valid_dir_in=os.path.join(in_dir, 'valid')\n",
    "test_dir_in=os.path.join(in_dir, 'test')\n",
    "\n",
    "train_dir_out=os.path.join(out_dir, \"train\")\n",
    "valid_dir_out=os.path.join(out_dir, 'valid')\n",
    "test_dir_out=os.path.join(out_dir, 'test')\n",
    "\n",
    "if not os.path.exists(train_dir_out):\n",
    "    os.makedirs(train_dir_out)\n",
    "if not os.path.exists(valid_dir_out):\n",
    "    os.makedirs(valid_dir_out)\n",
    "if not os.path.exists(test_dir_out):\n",
    "    os.makedirs(test_dir_out)\n",
    "\n",
    "if not os.path.exists(train_dir_in):\n",
    "    os.makedirs(train_dir_in)\n",
    "if not os.path.exists(valid_dir_in):\n",
    "    os.makedirs(valid_dir_in)\n",
    "if not os.path.exists(test_dir_in):\n",
    "    os.makedirs(test_dir_in)\n",
    "\n",
    "extract_regions(data_loc=test_dir_in, label_loc=label_loc, out_dir=test_dir_out, im_size=32, model=model, min_dist=2, samples_needed=400)\n",
    "extract_regions(data_loc=train_dir_in, label_loc=label_loc, out_dir=train_dir_out, im_size=32, model=model, min_dist=2, samples_needed=400)\n",
    "extract_regions(data_loc=valid_dir_in, label_loc=label_loc, out_dir=valid_dir_out, im_size=32, model=model, min_dist=2,  samples_needed=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Semi normal data\n",
    "The method attempted from the paper didn't work. Instead use the method we know got F score of .77 combined with some of the new method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_heatmap_L(image_loc, model, height, downsample):\n",
    "    def softmax(x):\n",
    "        e_x = np.exp(x - np.max(x))\n",
    "        return e_x / e_x.sum()\n",
    "    image = np.asarray(Image.open(image_loc))[:,:,:3]\n",
    "    image_shape = image.shape\n",
    "    image = image/255.0 # During training the images were normalized\n",
    "    height = int(height)\n",
    "\n",
    "    last = model.layers[-2].output\n",
    "    model = Model(model.input, last)\n",
    "\n",
    "    out_shape = np.ceil(np.array(image.shape)/float(downsample)).astype(int)\n",
    "    out_shape[2] = 2 # there are 2 classes\n",
    "\n",
    "    delta=int((height)/2)\n",
    "    image = np.lib.pad(image, ((delta, delta-int(downsample)), (delta, delta-int(downsample)), (0,0)), 'constant', constant_values=(0, 0))\n",
    "    image = np.expand_dims(image, axis=0)\n",
    "    heat = model.predict(image, batch_size=1, verbose=0)\n",
    "    heat = np.reshape(heat, out_shape)\n",
    "    # now apply the softmax to only the 3 classes(not the overall class probability (why??))\n",
    "    heat[:,:,:] = np.apply_along_axis(softmax, 2, heat[:,:,:])\n",
    "    return heat[:,:,1]\n",
    "\n",
    "\n",
    "def extract_regions_n2(data_loc, label_loc, out_dir, im_size, model, min_dist=2, samples_needed=80):\n",
    "    im_size=int(im_size)\n",
    "    \n",
    "    all_locs = glob.glob(os.path.join(data_loc, '*'))\n",
    "    folder_size = len(all_locs)\n",
    "    print('folder_size: ', folder_size)\n",
    "    \n",
    "    all_labels=glob.glob(os.path.join(label_loc, '*'))\n",
    "    all_labels = [loc for loc in all_labels if loc.rsplit('.', 1)[0][-1] == 'm']\n",
    "\n",
    "    for image_file in all_locs:\n",
    "        image = np.array(Image.open(image_file))[:,:,:3]\n",
    "        \n",
    "        # pad the image so you can always take the proper sized image\n",
    "        delta=int((im_size)/2)\n",
    "        image = np.lib.pad(image, ((delta, delta), (delta, delta), (0,0)), 'constant', constant_values=(0, 0))\n",
    "        \n",
    "        # get the labels. Find matching label image, and extract the coordinates:\n",
    "        img_num = image_file.rsplit('/', 1)[1].rsplit('.',1)[0][2:]\n",
    "        label_loc = next(loc for loc in all_labels if loc.rsplit('/', 1)[1].rsplit('.',1)[0][:-1]==img_num)\n",
    "\n",
    "        label_img = np.asarray(Image.open(label_loc))\n",
    "        label_list = np.asarray(np.where(label_img[:, :, 3]==255))\n",
    "        label_list = np.transpose(label_list)\n",
    "        \n",
    "        num_pos = 0\n",
    "        for point in label_list:\n",
    "            y = point[0] + delta\n",
    "            x = point[1] + delta\n",
    "\n",
    "            seg_image = image[y-delta:y+delta, x-delta:x+delta,:]\n",
    "            out_name=str(1)+'_'+str(num_pos)+'_'+img_num+'.jpg'\n",
    "\n",
    "            outfile=os.path.join(out_dir, out_name)\n",
    "            scipy.misc.imsave(outfile, seg_image)\n",
    "            num_pos = num_pos+1\n",
    "    \n",
    "        # evenly sample the negatives from every image:\n",
    "        samp_taken = 0\n",
    "        while (samp_taken < samples_needed):\n",
    "            row = random.randint(delta, image.shape[0]-delta)\n",
    "            col = random.randint(delta, image.shape[1]-delta)\n",
    "            proposed_center = np.array([row, col])\n",
    "            dists = np.sqrt(np.sum((label_list - proposed_center) ** 2, axis=1))\n",
    "            min_ind = np.argmin(dists)\n",
    "            if (dists[min_ind] > min_dist):\n",
    "                seg_image = image[row-delta:row+delta, col-delta:col+delta,:]\n",
    "                out_name=str(0)+'_'+str(samp_taken)+'_'+img_num+'.jpg'\n",
    "                outfile=os.path.join(out_dir, out_name)\n",
    "                scipy.misc.imsave(outfile, seg_image)\n",
    "                samp_taken=samp_taken+1\n",
    "                \n",
    "        # Sample from the hard locations:\n",
    "        heatmap = create_heatmap_L(image_file, model=model, height=im_size, downsample=2)\n",
    "        # upsample to make everything easier\n",
    "        heatmap = scipy.misc.imresize(heatmap, (100, 100))\n",
    "\n",
    "        # Remove the true points\n",
    "        heatmap = np.lib.pad(heatmap, ((3, 3), (3, 3)), 'constant', constant_values=(0, 0))\n",
    "        for point in label_list:\n",
    "            for row in range(-1*min_dist, min_dist+1, 1):\n",
    "                for col in range(-1*min_dist, min_dist+1, 1):\n",
    "                    # dont't just do a square\n",
    "                    dist = np.sqrt(row** 2 + col** 2)\n",
    "                    if (dist<=min_dist+.5):\n",
    "                        try:\n",
    "                            # classifier predicted top left point, so by adding 1 this centers it a bit better\n",
    "                            heatmap[int(point[0]+row+1), int(point[1]+col+1)] = 0 \n",
    "                        except Exception:\n",
    "                            continue\n",
    "        heatmap = heatmap[3:-3, 3:-3]\n",
    "        \n",
    "        # get the top samples_needed points, sample samples_needed/2 of them\n",
    "        sample_point_list = np.unravel_index(np.argsort(heatmap.ravel())[-int(200):], heatmap.shape)\n",
    "        sample_point_list = np.transpose(np.asarray(sample_point_list))\n",
    "        idx = np.random.choice(len(sample_point_list), int(samples_needed/2))\n",
    "        sample_point_list = sample_point_list[idx]\n",
    "\n",
    "        for point in sample_point_list:\n",
    "            y = point[0] + delta\n",
    "            x = point[1] + delta\n",
    "            seg_image = image[y-delta:y+delta, x-delta:x+delta,:]\n",
    "\n",
    "            out_name=str(0)+'_'+str(num_pos)+'_'+img_num+'.jpg'\n",
    "            outfile=os.path.join(out_dir, out_name)\n",
    "            scipy.misc.imsave(outfile, seg_image)\n",
    "            num_pos = num_pos+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder_size:  20\n",
      "folder_size:  65\n",
      "folder_size:  15\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import load_model, Model\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '/Users/rb/Google_Drive/Waterloo/projects/cancer_hist/src')\n",
    "from functions import*\n",
    "from heat_models import*\n",
    "\n",
    "in_dir='/Users/rb/Documents/waterloo/projects/cancer_hist/lymphocyte/ttv_split/'\n",
    "label_loc='/Users/rb/Documents/waterloo/projects/cancer_hist/lymphocyte/manual_seg/center/'\n",
    "out_dir='/Users/rb/Documents/waterloo/projects/cancer_hist/lymphocyte/extracted_new2_64_160'\n",
    "\n",
    "model_loc='/Users/rb/Google_Drive/Waterloo/projects/cancer_hist/output/lymphocyte/conv_incp3_l/conv_incp3_64_.41-0.97.hdf5'\n",
    "# model_loc='/Users/rb/Google_Drive/Waterloo/projects/cancer_hist/output/lymphocyte/conv_incp3_l_32/conv_incp3_32_.20-0.96.hdf5'\n",
    "\n",
    "model = conv_incp3(im_size=64)\n",
    "model.load_weights(model_loc)\n",
    "\n",
    "# First make the folders:\n",
    "train_dir_in=os.path.join(in_dir, \"train\")\n",
    "valid_dir_in=os.path.join(in_dir, 'valid')\n",
    "test_dir_in=os.path.join(in_dir, 'test')\n",
    "\n",
    "train_dir_out=os.path.join(out_dir, \"train\")\n",
    "valid_dir_out=os.path.join(out_dir, 'valid')\n",
    "test_dir_out=os.path.join(out_dir, 'test')\n",
    "\n",
    "if not os.path.exists(train_dir_out):\n",
    "    os.makedirs(train_dir_out)\n",
    "if not os.path.exists(valid_dir_out):\n",
    "    os.makedirs(valid_dir_out)\n",
    "if not os.path.exists(test_dir_out):\n",
    "    os.makedirs(test_dir_out)\n",
    "\n",
    "if not os.path.exists(train_dir_in):\n",
    "    os.makedirs(train_dir_in)\n",
    "if not os.path.exists(valid_dir_in):\n",
    "    os.makedirs(valid_dir_in)\n",
    "if not os.path.exists(test_dir_in):\n",
    "    os.makedirs(test_dir_in)\n",
    "\n",
    "extract_regions_n2(data_loc=test_dir_in, label_loc=label_loc, out_dir=test_dir_out, im_size=64, model=model, min_dist=2, samples_needed=160)\n",
    "extract_regions_n2(data_loc=train_dir_in, label_loc=label_loc, out_dir=train_dir_out, im_size=64, model=model, min_dist=2, samples_needed=160)\n",
    "extract_regions_n2(data_loc=valid_dir_in, label_loc=label_loc, out_dir=valid_dir_out, im_size=64, model=model, min_dist=2,  samples_needed=160)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
